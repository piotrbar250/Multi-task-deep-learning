{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077df0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
    "# !unzip data_gsn.zip &> /dev/null\n",
    "# !rm data_gsn.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3cd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c13152",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = [(i, j) for i in range(6) for j in range(i + 1, 6)]\n",
    "pair_to_idx = {p: k for k, p in enumerate(all_pairs)}\n",
    "\n",
    "def class_id_to_pair_and_split(class_id: int):\n",
    "    pair_idx = class_id // 9\n",
    "    split_idx = class_id % 9\n",
    "    ca = split_idx + 1\n",
    "    cb = 10 - ca\n",
    "    i, j = all_pairs[pair_idx]\n",
    "    return (i, j), (ca, cb)\n",
    "\n",
    "def class_id_to_pair(class_id: int):\n",
    "    pair_idx = class_id // 9\n",
    "    return all_pairs[pair_idx]\n",
    "\n",
    "def counts_to_class_id(counts):\n",
    "    if isinstance(counts, torch.Tensor):\n",
    "        c = counts.detach().cpu().tolist()\n",
    "    else:\n",
    "        c = list(counts)\n",
    "\n",
    "    nz = [i for i, v in enumerate(c) if v > 0]\n",
    "  \n",
    "    a, b = sorted(nz)\n",
    "    ca = int(c[a])\n",
    "    pair_index = pair_to_idx[(a, b)]\n",
    "\n",
    "    class_id = pair_index * 9 + (ca - 1)\n",
    "    return class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSN(Dataset):\n",
    "    def __init__(self, root, transform=None, transform_relabel=None):\n",
    "        self.data_dir = os.path.join(root, \"data\")\n",
    "        self.transform = transform\n",
    "        self.transform_relabel = transform_relabel\n",
    "\n",
    "        df = pd.read_csv(os.path.join(self.data_dir, \"labels.csv\"))\n",
    "        self.names = df[\"name\"].tolist()\n",
    "        cols = [\"squares\", \"circles\", \"up\", \"right\", \"down\", \"left\"]\n",
    "        self.labels = torch.tensor(df[cols].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name = self.names[index]\n",
    "        img_path = os.path.join(self.data_dir, name)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        img = transforms.ToTensor()(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        cnt = self.labels[index]\n",
    "\n",
    "        if self.transform_relabel:\n",
    "            img, cnt = self.transform_relabel(img, cnt)\n",
    "        \n",
    "        cls = counts_to_class_id(cnt)\n",
    "\n",
    "        return img, cls, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation:\n",
    "    def __init__(self, p_hflip=0.5, p_vflip=0.5):\n",
    "        self.p_hflip = p_hflip\n",
    "        self.p_vflip = p_vflip\n",
    "\n",
    "    def __call__(self, img, cnt):\n",
    "        cnt = cnt.clone()\n",
    "\n",
    "        k = torch.randint(0, 4, (1,)).item()\n",
    "        if k > 0:\n",
    "            img = torch.rot90(img, k=-k, dims=[1,2])\n",
    "            dirs = cnt[2:6]\n",
    "            dirs = torch.roll(dirs, shifts=k)\n",
    "            cnt[2:6] = dirs\n",
    "\n",
    "        if torch.rand(1).item() < self.p_hflip:\n",
    "            img = torch.flip(img, dims=[2])\n",
    "            cnt[[3, 5]] = cnt[[5, 3]]\n",
    "        \n",
    "        if torch.rand(1).item() < self.p_vflip:\n",
    "            img = torch.flip(img, dims=[1])\n",
    "            cnt[[2, 4]] = cnt[[4, 2]]\n",
    "\n",
    "        return img, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, cls_hidden=256, cnt_hidden=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(),     \n",
    "            nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(),   \n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(64 * 28 * 28, 256), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.head_cls = nn.Sequential(\n",
    "            nn.Linear(256, cls_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(cls_hidden, 135),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.head_cnt = nn.Sequential(\n",
    "            nn.Linear(256, cnt_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cnt_hidden, 6)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        cls = self.head_cls(x)\n",
    "        cnt = self.head_cnt(x)\n",
    "\n",
    "        return cls, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4775f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    net: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    mode: str,\n",
    "    lambda_cnt = None,\n",
    "):\n",
    "    net.train()\n",
    "    total_loss = 0.0\n",
    "    n_total = 0\n",
    "    \n",
    "    for img, cls_target, cnt_target in train_loader:\n",
    "        img, cls_target, cnt_target = img.to(device), cls_target.long().to(device), cnt_target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cls_pred, cnt_pred = net(img)\n",
    "        \n",
    "        cls_loss = F.nll_loss(cls_pred, cls_target)\n",
    "        cnt_loss = F.smooth_l1_loss(cnt_pred, cnt_target)\n",
    "\n",
    "        if mode == \"cls_only\":\n",
    "            loss = cls_loss\n",
    "        elif mode == \"reg_only\":\n",
    "            loss = cnt_loss\n",
    "        else:\n",
    "            loss = cls_loss + lambda_cnt * cnt_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        B = len(img)\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        n_total += B\n",
    "\n",
    "    epoch_loss = total_loss / n_total\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(\n",
    "    net: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    epoch: int,\n",
    "    mode: str,\n",
    "    lambda_cnt = None,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    net.eval()\n",
    "    total_loss = total_cls_loss = total_cnt_loss = 0.0\n",
    "    n_total = 0\n",
    "    correct = 0\n",
    "\n",
    "    sum_sq_diff = 0.0\n",
    "    n_cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, cls_target, cnt_target in test_loader:\n",
    "            img, cls_target, cnt_target = img.to(device), cls_target.long().to(device), cnt_target.to(device)\n",
    "\n",
    "            cls_pred, cnt_pred = net(img)\n",
    "\n",
    "            cls_loss = F.nll_loss(cls_pred, cls_target)\n",
    "            cnt_loss = F.smooth_l1_loss(cnt_pred, cnt_target)\n",
    "\n",
    "            if mode == \"cls_only\":\n",
    "                loss = cls_loss\n",
    "            elif mode == \"reg_only\":\n",
    "                loss = cnt_loss\n",
    "            else:\n",
    "                loss = cls_loss + lambda_cnt * cnt_loss\n",
    "\n",
    "            total_loss += loss.item() * len(img)\n",
    "            total_cls_loss += cls_loss.item() * len(img)\n",
    "            total_cnt_loss += cnt_loss.item() * len(img)\n",
    "            n_total += len(img)\n",
    "\n",
    "            pred = cls_pred.argmax(dim=1)\n",
    "            correct += (pred == cls_target).sum().item()\n",
    "\n",
    "            diff = cnt_pred - cnt_target\n",
    "            sum_sq_diff += (diff ** 2).sum().item()\n",
    "            n_cnt += diff.numel()\n",
    "\n",
    "    epoch_loss = total_loss / n_total\n",
    "    epoch_cls_loss = total_cls_loss / n_total\n",
    "    epoch_cnt_loss = total_cnt_loss / n_total\n",
    "    epoch_acc = correct / n_total\n",
    "\n",
    "    epoch_rmse = (sum_sq_diff / n_cnt) ** 0.5\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Eval Epoch: {epoch} | \"\n",
    "            f\"acc: {epoch_acc:.4f} | \"\n",
    "            f\"loss: {epoch_loss:.4f} | \"\n",
    "            f\"cls_loss: {epoch_cls_loss:.4f} | \"\n",
    "            f\"cnt_loss: {epoch_cnt_loss:.4f}\"\n",
    "        )\n",
    "    return epoch_loss, epoch_acc, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7dab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(net, device, loader):\n",
    "    net.eval()\n",
    "\n",
    "    all_cls_true = []\n",
    "    all_cls_pred = []\n",
    "    all_cnt_true = []\n",
    "    all_cnt_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, cls_target, cnt_target in loader:\n",
    "            img = img.to(device)\n",
    "\n",
    "            cls_logits, cnt_pred = net(img)\n",
    "            cls_pred = cls_logits.argmax(dim=1)\n",
    "\n",
    "            all_cls_true.append(cls_target)\n",
    "            all_cls_pred.append(cls_pred.to(\"cpu\"))            \n",
    "            all_cnt_true.append(cnt_target)\n",
    "            all_cnt_pred.append(cnt_pred.to(\"cpu\"))\n",
    "\n",
    "    cls_true = torch.cat(all_cls_true)\n",
    "    cls_pred = torch.cat(all_cls_pred)\n",
    "    cnt_true = torch.cat(all_cnt_true)\n",
    "    cnt_pred = torch.cat(all_cnt_pred)\n",
    "\n",
    "    acc = (cls_true == cls_pred).float().mean().item()\n",
    "    print(f\"Top-1 accuracy: {acc}\" )  \n",
    "\n",
    "    cls_true_np = cls_true.numpy() \n",
    "    cls_pred_np = cls_pred.numpy() \n",
    "    macro_f1 = f1_score(cls_true_np, cls_pred_np, average=\"macro\")\n",
    "    print(f\"Macro F1:{macro_f1}\")\n",
    "\n",
    "    correct_pair = 0\n",
    "    total = len(cls_true)\n",
    "    for t, p in zip(cls_true.tolist(), cls_pred.tolist()):\n",
    "        if class_id_to_pair(int(t)) == class_id_to_pair(int(p)):\n",
    "            correct_pair += 1\n",
    "    pair_acc = correct_pair / total\n",
    "    print(f\"Per-pair accuracy: {pair_acc}\")\n",
    "\n",
    "    diff = cnt_pred - cnt_true\n",
    "    mse_per_class = (diff ** 2).mean(dim=0)\n",
    "    rmse_per_class = torch.sqrt(mse_per_class)\n",
    "    mae_per_class = diff.abs().mean(dim=0)\n",
    "    overall_rmse = torch.sqrt((diff ** 2).mean()).item()\n",
    "    overall_mae = diff.abs().mean().item()  \n",
    "    print(f\"RMSE per class: {rmse_per_class.tolist()}\")\n",
    "    print(f\"MAE per class: {mae_per_class.tolist()}\")\n",
    "    print(f\"Overall RMSE: {overall_rmse}\")\n",
    "    print(f\"Overall MAE: {overall_mae}\")\n",
    "\n",
    "    cm = confusion_matrix(cls_true_np, cls_pred_np, labels=np.arange(135))\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"pair_acc\": pair_acc,\n",
    "        \"rmse_per_class\": rmse_per_class.tolist(),\n",
    "        \"mae_per_class\": mae_per_class.tolist(),\n",
    "        \"overall_rmse\": overall_rmse,\n",
    "        \"overall_mae\": overall_mae,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf72c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(root=\".\", batch_size=64, test_batch_size=1000, device=torch.device(\"cpu\")):\n",
    "    if device.type == \"cuda\":\n",
    "        num_workers = min(8, os.cpu_count() or 2)\n",
    "    else:\n",
    "        num_workers = 0\n",
    "\n",
    "    pin = (device.type == \"cuda\")\n",
    "    loader_kwargs = dict(\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    if num_workers > 0:\n",
    "        loader_kwargs[\"prefetch_factor\"] = 4\n",
    "\n",
    "    train_aug = Augmentation()\n",
    "    train_full = GSN(root=root, transform_relabel=train_aug)\n",
    "    test_full = GSN(root=root)\n",
    "\n",
    "    train_dataset = Subset(train_full, range(0, 9000))\n",
    "    test_dataset = Subset(test_full, range(9000, 10000))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **loader_kwargs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **loader_kwargs)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9897ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "cls_hidden = 256\n",
    "cnt_hidden = 256\n",
    "dropout = 0.3\n",
    "patience = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(\n",
    "    mode: str,\n",
    "    lambda_cnt = None,\n",
    "):\n",
    "    if device.type == \"cuda\":\n",
    "        torch.backends.cudnn.conv.fp32_precision = 'tf32'\n",
    "\n",
    "\n",
    "    train_loader, test_loader = create_loaders(\n",
    "        root=\".\",\n",
    "        batch_size=64,\n",
    "        test_batch_size=1000,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    net = NeuralNetwork(cls_hidden, cnt_hidden, dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"eval_loss\": [],\n",
    "        \"eval_acc\": [],\n",
    "        \"eval_rmse\": [],\n",
    "    }\n",
    "\n",
    "    best_eval_loss = float(\"inf\")\n",
    "    best_eval_loss_acc = 0.0\n",
    "    best_state = None\n",
    "    bad_epochs = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = train_epoch(\n",
    "            net,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            mode,\n",
    "            lambda_cnt=lambda_cnt,\n",
    "        )\n",
    "\n",
    "        eval_loss, eval_acc, eval_rmse = eval_epoch(\n",
    "            net,\n",
    "            device,\n",
    "            test_loader,\n",
    "            epoch,\n",
    "            mode,\n",
    "            lambda_cnt=lambda_cnt,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"eval_loss\"].append(eval_loss)\n",
    "        history[\"eval_acc\"].append(eval_acc)\n",
    "        history[\"eval_rmse\"].append(eval_rmse)\n",
    "\n",
    "        if eval_loss < best_eval_loss - 1e-4:\n",
    "            best_eval_loss = eval_loss\n",
    "            best_eval_loss_acc = eval_acc\n",
    "            best_state = {k: v.cpu().clone() for k,v in net.state_dict().items()}\n",
    "            bad_epochs = 0\n",
    "            best_epoch = epoch\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "            if bad_epochs >= patience:\n",
    "                print(\n",
    "                    f\"Early stop at epoch {epoch}. \"\n",
    "                    f\"Best val loss: {best_eval_loss:.4f}, \"\n",
    "                    f\"with acc: {best_eval_loss_acc:.4f}, \"\n",
    "                    f\"after epoch: {best_epoch}\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        net.load_state_dict(best_state)\n",
    "\n",
    "    metrics = evaluate_metrics(net, device, test_loader)\n",
    "\n",
    "    return net, history, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08caeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "settings = [\n",
    "    (\"cls_only\", None),\n",
    "    (\"reg_only\", None),\n",
    "    (\"multitask\", 0.3),\n",
    "    (\"multitask\", 0.5),\n",
    "    (\"multitask\", 1.0),\n",
    "]\n",
    "\n",
    "for mode, lambda_cnt in settings:\n",
    "    if lambda_cnt is not None:\n",
    "        print(f\"\\n=== Training mode={mode}, lambda_cnt={lambda_cnt} ===\")\n",
    "        net, history, metrics = train_model(mode=mode, lambda_cnt=lambda_cnt)\n",
    "\n",
    "        results[(mode, lambda_cnt)] = {\n",
    "            \"history\": history,\n",
    "            \"metrics\": metrics,\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n=== Training mode={mode} ===\")\n",
    "        net, history, metrics = train_model(mode=mode)\n",
    "\n",
    "        results[mode] = {\n",
    "            \"history\": history,\n",
    "            \"metrics\": metrics,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b821c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_models(settings, save_dir=None):\n",
    "    results = {}\n",
    "\n",
    "    for mode, lambda_cnt in settings:\n",
    "        if lambda_cnt is not None:\n",
    "            print(f\"\\n=== Training mode={mode}, lambda_cnt={lambda_cnt} ===\")\n",
    "            net, history, metrics = train_model(mode=mode, lambda_cnt=lambda_cnt)\n",
    "\n",
    "            results[(mode, lambda_cnt)] = {\n",
    "                \"history\": history,\n",
    "                \"metrics\": metrics,\n",
    "            }\n",
    "\n",
    "            lambda_str = str(lambda_cnt).replace(\".\", \"_\")\n",
    "            model_path = os.path.join(save_dir, f\"model_{mode}_lambda{lambda_str}.pt\")\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f\"Saved model to {model_path}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n=== Training mode={mode} ===\")\n",
    "            net, history, metrics = train_model(mode=mode)\n",
    "\n",
    "            results[mode] = {\n",
    "                \"history\": history,\n",
    "                \"metrics\": metrics,\n",
    "            }\n",
    "\n",
    "            model_path = os.path.join(save_dir, f\"model_{mode}.pt\")\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f\"Saved model to {model_path}\")\n",
    "\n",
    "    results_path = os.path.join(save_dir, \"results.pkl\")\n",
    "    with open(results_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"\\nSaved all results dict to {results_path}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = [\n",
    "    (\"cls_only\", None),\n",
    "    (\"reg_only\", None),\n",
    "    (\"multitask\", 0.3),\n",
    "    (\"multitask\", 0.5),\n",
    "    (\"multitask\", 1.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for key, res in results.items():\n",
    "    if isinstance(key, tuple):\n",
    "        mode, lambda_cnt = key\n",
    "    else:\n",
    "        mode, lambda_cnt = key, None\n",
    "\n",
    "    m = res[\"metrics\"]\n",
    "    rows.append({\n",
    "        \"mode\": mode,\n",
    "        \"lambda_cnt\": lambda_cnt,\n",
    "        \"acc\": m[\"acc\"],\n",
    "        \"macro_f1\": m[\"macro_f1\"],\n",
    "        \"pair_acc\": m[\"pair_acc\"],\n",
    "        \"overall_rmse\": m[\"overall_rmse\"],\n",
    "        \"overall_mae\": m[\"overall_mae\"],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c627d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "index = []\n",
    "shape_classes = [\"square\", \"circle\", \"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "for key, res in results.items():\n",
    "    if isinstance(key, tuple):\n",
    "        mode, lambda_cnt = key\n",
    "    else:\n",
    "        mode, lambda_cnt = key, None\n",
    "\n",
    "    m = res[\"metrics\"]\n",
    "    rmse_vals = m[\"rmse_per_class\"]\n",
    "    mae_vals = m[\"mae_per_class\"]\n",
    "\n",
    "    index.append((mode, lambda_cnt, \"rmse\"))\n",
    "    rows.append(rmse_vals)\n",
    "\n",
    "    index.append((mode, lambda_cnt, \"mae\"))\n",
    "    rows.append(mae_vals)\n",
    "\n",
    "multi_index = pd.MultiIndex.from_tuples(\n",
    "    index, names=[\"mode\", \"lambda_cnt\", \"metric\"]\n",
    ")\n",
    "\n",
    "per_class_all_df = pd.DataFrame(rows, index=multi_index, columns=shape_classes)\n",
    "per_class_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_full(cm, title=\"Confusion matrix (135 classes)\"):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    ax.set_xlabel(\"Predicted class\")\n",
    "    ax.set_ylabel(\"True class\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80347991",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_key = (\"multitask\", 0.3)\n",
    "cm = results[mt_key][\"metrics\"][\"confusion_matrix\"]\n",
    "plot_confusion_matrix_full(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history, mode, title_prefix=\"\"):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(epochs, history[\"train_loss\"], label=\"Train loss\")\n",
    "    ax.plot(epochs, history[\"eval_loss\"], label=\"Val loss\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(f\"{title_prefix}Loss over epochs\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if mode != \"reg_only\":\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(epochs, history[\"eval_acc\"])\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title(f\"{title_prefix}Validation accuracy over epochs\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if mode != \"cls_only\":\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(epochs, history[\"eval_rmse\"])\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"RMSE\")\n",
    "        ax.set_title(f\"{title_prefix}Validation RMSE over epochs\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dd627",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results[\"reg_only\"][\"history\"], mode=\"reg_only\", title_prefix=\"[reg_only] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results[\"cls_only\"][\"history\"], mode=\"cls_only\", title_prefix=\"[cls_only] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0241b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results[(\"multitask\", 0.3)][\"history\"], mode=\"multitask\", title_prefix=\"[multitask λ=0.3] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results[(\"multitask\", 0.5)][\"history\"], mode=\"multitask\", title_prefix=\"[multitask λ=0.5] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5529e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results[(\"multitask\", 1.0)][\"history\"], mode=\"multitask\", title_prefix=\"[multitask λ=1.0] \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
