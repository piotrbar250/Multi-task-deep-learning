{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077df0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
    "# !unzip data_gsn.zip &> /dev/null\n",
    "# !rm data_gsn.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3cd8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1928071770>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c13152",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = [(i, j) for i in range(6) for j in range(i + 1, 6)]\n",
    "pair_to_idx = {p: k for k, p in enumerate(all_pairs)}\n",
    "\n",
    "def class_id_to_pair_and_split(class_id: int):\n",
    "    pair_idx = class_id // 9\n",
    "    split_idx = class_id % 9\n",
    "    ca = split_idx + 1\n",
    "    cb = 10 - ca\n",
    "    i, j = all_pairs[pair_idx]\n",
    "    return (i, j), (ca, cb)\n",
    "\n",
    "def class_id_to_pair(class_id: int):\n",
    "    pair_idx = class_id // 9\n",
    "    return all_pairs[pair_idx]\n",
    "\n",
    "def counts_to_class_id(counts):\n",
    "    if isinstance(counts, torch.Tensor):\n",
    "        c = counts.detach().cpu().tolist()\n",
    "    else:\n",
    "        c = list(counts)\n",
    "\n",
    "    nz = [i for i, v in enumerate(c) if v > 0]\n",
    "  \n",
    "    a, b = sorted(nz)\n",
    "    ca = int(c[a])\n",
    "    pair_index = pair_to_idx[(a, b)]\n",
    "\n",
    "    class_id = pair_index * 9 + (ca - 1)\n",
    "    return class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cf7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSN(Dataset):\n",
    "    def __init__(self, root, transform=None, transform_relabel=None):\n",
    "        self.data_dir = os.path.join(root, \"data\")\n",
    "        self.transform = transform\n",
    "        self.transform_relabel = transform_relabel\n",
    "\n",
    "        df = pd.read_csv(os.path.join(self.data_dir, \"labels.csv\"))\n",
    "        self.names = df[\"name\"].tolist()\n",
    "        cols = [\"squares\", \"circles\", \"up\", \"right\", \"down\", \"left\"]\n",
    "        self.labels = torch.tensor(df[cols].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name = self.names[index]\n",
    "        img_path = os.path.join(self.data_dir, name)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        img = transforms.ToTensor()(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        cnt = self.labels[index]\n",
    "\n",
    "        if self.transform_relabel:\n",
    "            img, cnt = self.transform_relabel(img, cnt)\n",
    "        \n",
    "        cls = counts_to_class_id(cnt)\n",
    "\n",
    "        return img, cls, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5db8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation:\n",
    "    def __init__(self, p_hflip=0.5, p_vflip=0.5):\n",
    "        self.p_hflip = p_hflip\n",
    "        self.p_vflip = p_vflip\n",
    "\n",
    "    def __call__(self, img, cnt):\n",
    "        cnt = cnt.clone()\n",
    "\n",
    "        k = torch.randint(0, 4, (1,)).item()\n",
    "        if k > 0:\n",
    "            img = torch.rot90(img, k=-k, dims=[1,2])\n",
    "            dirs = cnt[2:6]\n",
    "            dirs = torch.roll(dirs, shifts=k)\n",
    "            cnt[2:6] = dirs\n",
    "\n",
    "        if torch.rand(1).item() < self.p_hflip:\n",
    "            img = torch.flip(img, dims=[2])\n",
    "            cnt[[3, 5]] = cnt[[5, 3]]\n",
    "        \n",
    "        if torch.rand(1).item() < self.p_vflip:\n",
    "            img = torch.flip(img, dims=[1])\n",
    "            cnt[[2, 4]] = cnt[[4, 2]]\n",
    "\n",
    "        return img, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6103b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, cls_hidden=256, cnt_hidden=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(),     \n",
    "            nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(),   \n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(64 * 28 * 28, 256), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.head_cls = nn.Sequential(\n",
    "            nn.Linear(256, cls_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(cls_hidden, 135),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.head_cnt = nn.Sequential(\n",
    "            nn.Linear(256, cnt_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cnt_hidden, 6)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        cls = self.head_cls(x)\n",
    "        cnt = self.head_cnt(x)\n",
    "\n",
    "        return cls, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4775f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    net: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    mode: str,\n",
    "    lambda_cnt = None,\n",
    "):\n",
    "    net.train()\n",
    "    total_loss = 0.0\n",
    "    n_total = 0\n",
    "    \n",
    "    for img, cls_target, cnt_target in train_loader:\n",
    "        img, cls_target, cnt_target = img.to(device), cls_target.long().to(device), cnt_target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cls_pred, cnt_pred = net(img)\n",
    "        \n",
    "        cls_loss = F.nll_loss(cls_pred, cls_target)\n",
    "        cnt_loss = F.smooth_l1_loss(cnt_pred, cnt_target)\n",
    "\n",
    "        if mode == \"cls_only\":\n",
    "            loss = cls_loss\n",
    "        elif mode == \"reg_only\":\n",
    "            loss = cnt_loss\n",
    "        else:\n",
    "            loss = cls_loss + lambda_cnt * cnt_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        B = len(img)\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        n_total += B\n",
    "\n",
    "    epoch_loss = total_loss / n_total\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "437bc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(\n",
    "    net: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    epoch: int,\n",
    "    mode: str,\n",
    "    lambda_cnt = None,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    net.eval()\n",
    "    total_loss = total_cls_loss = total_cnt_loss = 0.0\n",
    "    n_total = 0\n",
    "    correct = 0\n",
    "\n",
    "    sum_sq_diff = 0.0\n",
    "    n_cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, cls_target, cnt_target in test_loader:\n",
    "            img, cls_target, cnt_target = img.to(device), cls_target.long().to(device), cnt_target.to(device)\n",
    "\n",
    "            cls_pred, cnt_pred = net(img)\n",
    "\n",
    "            cls_loss = F.nll_loss(cls_pred, cls_target)\n",
    "            cnt_loss = F.smooth_l1_loss(cnt_pred, cnt_target)\n",
    "\n",
    "            if mode == \"cls_only\":\n",
    "                loss = cls_loss\n",
    "            elif mode == \"reg_only\":\n",
    "                loss = cnt_loss\n",
    "            else:\n",
    "                loss = cls_loss + lambda_cnt * cnt_loss\n",
    "\n",
    "            total_loss += loss.item() * len(img)\n",
    "            total_cls_loss += cls_loss.item() * len(img)\n",
    "            total_cnt_loss += cnt_loss.item() * len(img)\n",
    "            n_total += len(img)\n",
    "\n",
    "            pred = cls_pred.argmax(dim=1)\n",
    "            correct += (pred == cls_target).sum().item()\n",
    "\n",
    "            diff = cnt_pred - cnt_target\n",
    "            sum_sq_diff += (diff ** 2).sum().item()\n",
    "            n_cnt += diff.numel()\n",
    "\n",
    "    epoch_loss = total_loss / n_total\n",
    "    epoch_cls_loss = total_cls_loss / n_total\n",
    "    epoch_cnt_loss = total_cnt_loss / n_total\n",
    "    epoch_acc = correct / n_total\n",
    "\n",
    "    epoch_rmse = (sum_sq_diff / n_cnt) ** 0.5\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Eval Epoch: {epoch} | \"\n",
    "            f\"acc: {epoch_acc:.4f} | \"\n",
    "            f\"loss: {epoch_loss:.4f} | \"\n",
    "            f\"cls_loss: {epoch_cls_loss:.4f} | \"\n",
    "            f\"cnt_loss: {epoch_cnt_loss:.4f}\"\n",
    "        )\n",
    "    return epoch_loss, epoch_acc, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7dab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(net, device, loader):\n",
    "    net.eval()\n",
    "\n",
    "    all_cls_true = []\n",
    "    all_cls_pred = []\n",
    "    all_cnt_true = []\n",
    "    all_cnt_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, cls_target, cnt_target in loader:\n",
    "            img = img.to(device)\n",
    "\n",
    "            cls_logits, cnt_pred = net(img)\n",
    "            cls_pred = cls_logits.argmax(dim=1)\n",
    "\n",
    "            all_cls_true.append(cls_target)\n",
    "            all_cls_pred.append(cls_pred.to(\"cpu\"))            \n",
    "            all_cnt_true.append(cnt_target)\n",
    "            all_cnt_pred.append(cnt_pred.to(\"cpu\"))\n",
    "\n",
    "    cls_true = torch.cat(all_cls_true)\n",
    "    cls_pred = torch.cat(all_cls_pred)\n",
    "    cnt_true = torch.cat(all_cnt_true)\n",
    "    cnt_pred = torch.cat(all_cnt_pred)\n",
    "\n",
    "    acc = (cls_true == cls_pred).float().mean().item()\n",
    "    print(f\"Top-1 accuracy: {acc}\" )  \n",
    "\n",
    "    cls_true_np = cls_true.numpy() \n",
    "    cls_pred_np = cls_pred.numpy() \n",
    "    macro_f1 = f1_score(cls_true_np, cls_pred_np, average=\"macro\")\n",
    "    print(f\"Macro F1:{macro_f1}\")\n",
    "\n",
    "    correct_pair = 0\n",
    "    total = len(cls_true)\n",
    "    for t, p in zip(cls_true.tolist(), cls_pred.tolist()):\n",
    "        if class_id_to_pair(int(t)) == class_id_to_pair(int(p)):\n",
    "            correct_pair += 1\n",
    "    pair_acc = correct_pair / total\n",
    "    print(f\"Per-pair accuracy: {pair_acc}\")\n",
    "\n",
    "    diff = cnt_pred - cnt_true\n",
    "    mse_per_class = (diff ** 2).mean(dim=0)\n",
    "    rmse_per_class = torch.sqrt(mse_per_class)\n",
    "    mae_per_class = diff.abs().mean(dim=0)\n",
    "    overall_rmse = torch.sqrt((diff ** 2).mean()).item()\n",
    "    overall_mae = diff.abs().mean().item()  \n",
    "    print(f\"RMSE per class: {rmse_per_class.tolist()}\")\n",
    "    print(f\"MAE per class: {mae_per_class.tolist()}\")\n",
    "    print(f\"Overall RMSE: {overall_rmse}\")\n",
    "    print(f\"Overall MAE: {overall_mae}\")\n",
    "\n",
    "    cm = confusion_matrix(cls_true_np, cls_pred_np, labels=np.arange(135))\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"pair_acc\": pair_acc,\n",
    "        \"rmse_per_class\": rmse_per_class.tolist(),\n",
    "        \"mae_per_class\": mae_per_class.tolist(),\n",
    "        \"overall_rmse\": overall_rmse,\n",
    "        \"overall_mae\": overall_mae,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf72c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(root=\".\", batch_size=64, test_batch_size=1000, device=torch.device(\"cpu\")):\n",
    "    if device.type == \"cuda\":\n",
    "        num_workers = min(8, os.cpu_count() or 2)\n",
    "    else:\n",
    "        num_workers = 0\n",
    "\n",
    "    pin = (device.type == \"cuda\")\n",
    "    loader_kwargs = dict(\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    if num_workers > 0:\n",
    "        loader_kwargs[\"prefetch_factor\"] = 4\n",
    "\n",
    "    train_aug = Augmentation()\n",
    "    train_full = GSN(root=root, transform_relabel=train_aug)\n",
    "    test_full = GSN(root=root)\n",
    "\n",
    "    train_dataset = Subset(train_full, range(0, 9000))\n",
    "    test_dataset = Subset(test_full, range(9000, 10000))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **loader_kwargs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **loader_kwargs)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9897ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "cls_hidden = 256\n",
    "cnt_hidden = 256\n",
    "dropout = 0.3\n",
    "patience = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(\n",
    "    mode: str,\n",
    "    lambda_cnt = None,\n",
    "):\n",
    "    if device.type == \"cuda\":\n",
    "        torch.backends.cudnn.conv.fp32_precision = 'tf32'\n",
    "\n",
    "\n",
    "    train_loader, test_loader = create_loaders(\n",
    "        root=\".\",\n",
    "        batch_size=64,\n",
    "        test_batch_size=1000,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    net = NeuralNetwork(cls_hidden, cnt_hidden, dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"eval_loss\": [],\n",
    "        \"eval_acc\": [],\n",
    "        \"eval_rmse\": [],\n",
    "    }\n",
    "\n",
    "    best_eval_loss = float(\"inf\")\n",
    "    best_eval_loss_acc = 0.0\n",
    "    best_state = None\n",
    "    bad_epochs = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = train_epoch(\n",
    "            net,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            mode,\n",
    "            lambda_cnt=lambda_cnt,\n",
    "        )\n",
    "\n",
    "        eval_loss, eval_acc, eval_rmse = eval_epoch(\n",
    "            net,\n",
    "            device,\n",
    "            test_loader,\n",
    "            epoch,\n",
    "            mode,\n",
    "            lambda_cnt=lambda_cnt,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"eval_loss\"].append(eval_loss)\n",
    "        history[\"eval_acc\"].append(eval_acc)\n",
    "        history[\"eval_rmse\"].append(eval_rmse)\n",
    "\n",
    "        if eval_loss < best_eval_loss - 1e-4:\n",
    "            best_eval_loss = eval_loss\n",
    "            best_eval_loss_acc = eval_acc\n",
    "            best_state = {k: v.cpu().clone() for k,v in net.state_dict().items()}\n",
    "            bad_epochs = 0\n",
    "            best_epoch = epoch\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "            if bad_epochs >= patience:\n",
    "                print(\n",
    "                    f\"Early stop at epoch {epoch}. \"\n",
    "                    f\"Best val loss: {best_eval_loss:.4f}, \"\n",
    "                    f\"with acc: {best_eval_loss_acc:.4f}, \"\n",
    "                    f\"after epoch: {best_epoch}\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        net.load_state_dict(best_state)\n",
    "\n",
    "    metrics = evaluate_metrics(net, device, test_loader)\n",
    "\n",
    "    return net, history, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b821c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_models(settings, save_dir=None):\n",
    "    results = {}\n",
    "\n",
    "    for mode, lambda_cnt in settings:\n",
    "        if lambda_cnt is not None:\n",
    "            print(f\"\\n=== Training mode={mode}, lambda_cnt={lambda_cnt} ===\")\n",
    "            net, history, metrics = train_model(mode=mode, lambda_cnt=lambda_cnt)\n",
    "\n",
    "            results[(mode, lambda_cnt)] = {\n",
    "                \"history\": history,\n",
    "                \"metrics\": metrics,\n",
    "            }\n",
    "\n",
    "            lambda_str = str(lambda_cnt).replace(\".\", \"_\")\n",
    "            model_path = os.path.join(save_dir, f\"model_{mode}_lambda{lambda_str}.pt\")\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f\"Saved model to {model_path}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n=== Training mode={mode} ===\")\n",
    "            net, history, metrics = train_model(mode=mode)\n",
    "\n",
    "            results[mode] = {\n",
    "                \"history\": history,\n",
    "                \"metrics\": metrics,\n",
    "            }\n",
    "\n",
    "            model_path = os.path.join(save_dir, f\"model_{mode}.pt\")\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f\"Saved model to {model_path}\")\n",
    "\n",
    "    results_path = os.path.join(save_dir, \"results.pkl\")\n",
    "    with open(results_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"\\nSaved all results dict to {results_path}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42db1878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training mode=cls_only ===\n",
      "Eval Epoch: 1 | acc: 0.0050 | loss: 4.6753 | cls_loss: 4.6753 | cnt_loss: 1.4908\n",
      "Eval Epoch: 2 | acc: 0.0130 | loss: 4.6208 | cls_loss: 4.6208 | cnt_loss: 1.5008\n",
      "Eval Epoch: 3 | acc: 0.0620 | loss: 3.6990 | cls_loss: 3.6990 | cnt_loss: 1.5497\n",
      "Eval Epoch: 4 | acc: 0.1420 | loss: 2.8057 | cls_loss: 2.8057 | cnt_loss: 1.6158\n",
      "Eval Epoch: 5 | acc: 0.2240 | loss: 2.3039 | cls_loss: 2.3039 | cnt_loss: 1.6251\n",
      "Eval Epoch: 6 | acc: 0.2360 | loss: 2.1355 | cls_loss: 2.1355 | cnt_loss: 1.6422\n",
      "Eval Epoch: 7 | acc: 0.3110 | loss: 1.8019 | cls_loss: 1.8019 | cnt_loss: 1.6492\n",
      "Eval Epoch: 8 | acc: 0.3480 | loss: 1.6831 | cls_loss: 1.6831 | cnt_loss: 1.6496\n",
      "Eval Epoch: 9 | acc: 0.3790 | loss: 1.5597 | cls_loss: 1.5597 | cnt_loss: 1.6477\n",
      "Eval Epoch: 10 | acc: 0.3540 | loss: 1.5707 | cls_loss: 1.5707 | cnt_loss: 1.6382\n",
      "Eval Epoch: 11 | acc: 0.3690 | loss: 1.5218 | cls_loss: 1.5218 | cnt_loss: 1.6609\n",
      "Eval Epoch: 12 | acc: 0.3870 | loss: 1.4730 | cls_loss: 1.4730 | cnt_loss: 1.6539\n",
      "Eval Epoch: 13 | acc: 0.4190 | loss: 1.4260 | cls_loss: 1.4260 | cnt_loss: 1.6396\n",
      "Eval Epoch: 14 | acc: 0.3820 | loss: 1.4102 | cls_loss: 1.4102 | cnt_loss: 1.6365\n",
      "Eval Epoch: 15 | acc: 0.4230 | loss: 1.3851 | cls_loss: 1.3851 | cnt_loss: 1.6411\n",
      "Eval Epoch: 16 | acc: 0.4480 | loss: 1.3322 | cls_loss: 1.3322 | cnt_loss: 1.6522\n",
      "Eval Epoch: 17 | acc: 0.4260 | loss: 1.4085 | cls_loss: 1.4085 | cnt_loss: 1.6424\n",
      "Eval Epoch: 18 | acc: 0.4470 | loss: 1.3308 | cls_loss: 1.3308 | cnt_loss: 1.6426\n",
      "Eval Epoch: 19 | acc: 0.4400 | loss: 1.2902 | cls_loss: 1.2902 | cnt_loss: 1.6442\n",
      "Eval Epoch: 20 | acc: 0.4430 | loss: 1.3042 | cls_loss: 1.3042 | cnt_loss: 1.6484\n",
      "Eval Epoch: 21 | acc: 0.3920 | loss: 1.4307 | cls_loss: 1.4307 | cnt_loss: 1.6421\n",
      "Eval Epoch: 22 | acc: 0.4500 | loss: 1.3368 | cls_loss: 1.3368 | cnt_loss: 1.6346\n",
      "Eval Epoch: 23 | acc: 0.4650 | loss: 1.2826 | cls_loss: 1.2826 | cnt_loss: 1.6351\n",
      "Eval Epoch: 24 | acc: 0.4850 | loss: 1.2291 | cls_loss: 1.2291 | cnt_loss: 1.6413\n",
      "Eval Epoch: 25 | acc: 0.4490 | loss: 1.2544 | cls_loss: 1.2544 | cnt_loss: 1.6249\n",
      "Eval Epoch: 26 | acc: 0.4810 | loss: 1.2490 | cls_loss: 1.2490 | cnt_loss: 1.6288\n",
      "Eval Epoch: 27 | acc: 0.4080 | loss: 1.4747 | cls_loss: 1.4747 | cnt_loss: 1.6328\n",
      "Eval Epoch: 28 | acc: 0.4630 | loss: 1.2789 | cls_loss: 1.2789 | cnt_loss: 1.6334\n",
      "Eval Epoch: 29 | acc: 0.4840 | loss: 1.2230 | cls_loss: 1.2230 | cnt_loss: 1.6296\n",
      "Eval Epoch: 30 | acc: 0.4980 | loss: 1.2272 | cls_loss: 1.2272 | cnt_loss: 1.6376\n",
      "Eval Epoch: 31 | acc: 0.4840 | loss: 1.2263 | cls_loss: 1.2263 | cnt_loss: 1.6339\n",
      "Eval Epoch: 32 | acc: 0.4740 | loss: 1.2655 | cls_loss: 1.2655 | cnt_loss: 1.6408\n",
      "Eval Epoch: 33 | acc: 0.4930 | loss: 1.2219 | cls_loss: 1.2219 | cnt_loss: 1.6363\n",
      "Eval Epoch: 34 | acc: 0.5030 | loss: 1.2729 | cls_loss: 1.2729 | cnt_loss: 1.6445\n",
      "Eval Epoch: 35 | acc: 0.4900 | loss: 1.2942 | cls_loss: 1.2942 | cnt_loss: 1.6296\n",
      "Eval Epoch: 36 | acc: 0.4980 | loss: 1.2844 | cls_loss: 1.2844 | cnt_loss: 1.6352\n",
      "Eval Epoch: 37 | acc: 0.5120 | loss: 1.1943 | cls_loss: 1.1943 | cnt_loss: 1.6230\n",
      "Eval Epoch: 38 | acc: 0.4900 | loss: 1.3017 | cls_loss: 1.3017 | cnt_loss: 1.6279\n",
      "Eval Epoch: 39 | acc: 0.4770 | loss: 1.3686 | cls_loss: 1.3686 | cnt_loss: 1.6403\n",
      "Eval Epoch: 40 | acc: 0.4600 | loss: 1.3982 | cls_loss: 1.3982 | cnt_loss: 1.6237\n",
      "Eval Epoch: 41 | acc: 0.5220 | loss: 1.2236 | cls_loss: 1.2236 | cnt_loss: 1.6254\n",
      "Eval Epoch: 42 | acc: 0.5210 | loss: 1.2662 | cls_loss: 1.2662 | cnt_loss: 1.6348\n",
      "Eval Epoch: 43 | acc: 0.5050 | loss: 1.2855 | cls_loss: 1.2855 | cnt_loss: 1.6358\n",
      "Eval Epoch: 44 | acc: 0.5180 | loss: 1.2974 | cls_loss: 1.2974 | cnt_loss: 1.6315\n",
      "Eval Epoch: 45 | acc: 0.5260 | loss: 1.3144 | cls_loss: 1.3144 | cnt_loss: 1.6268\n",
      "Eval Epoch: 46 | acc: 0.5420 | loss: 1.2916 | cls_loss: 1.2916 | cnt_loss: 1.6400\n",
      "Eval Epoch: 47 | acc: 0.5160 | loss: 1.3185 | cls_loss: 1.3185 | cnt_loss: 1.6322\n",
      "Early stop at epoch 47. Best val loss: 1.1943, with acc: 0.5120, after epoch: 37\n",
      "Top-1 accuracy: 0.5120000243186951\n",
      "Macro F1:0.48415950272499025\n",
      "Per-pair accuracy: 0.943\n",
      "RMSE per class: [3.232229709625244, 3.231872081756592, 3.081488847732544, 3.2640373706817627, 3.351954221725464, 3.19500732421875]\n",
      "MAE per class: [1.8422293663024902, 1.9299571514129639, 1.9322302341461182, 2.0161125659942627, 2.0927350521087646, 1.992254376411438]\n",
      "Overall RMSE: 3.227111339569092\n",
      "Overall MAE: 1.967586636543274\n",
      "Saved model to models/model_cls_only.pt\n",
      "\n",
      "=== Training mode=reg_only ===\n",
      "Eval Epoch: 1 | acc: 0.0110 | loss: 1.2404 | cls_loss: 4.9456 | cnt_loss: 1.2404\n",
      "Eval Epoch: 2 | acc: 0.0070 | loss: 0.9267 | cls_loss: 4.9869 | cnt_loss: 0.9267\n",
      "Eval Epoch: 3 | acc: 0.0060 | loss: 0.7788 | cls_loss: 5.0230 | cnt_loss: 0.7788\n",
      "Eval Epoch: 4 | acc: 0.0050 | loss: 0.5952 | cls_loss: 5.0056 | cnt_loss: 0.5952\n",
      "Eval Epoch: 5 | acc: 0.0070 | loss: 0.4321 | cls_loss: 4.9885 | cnt_loss: 0.4321\n",
      "Eval Epoch: 6 | acc: 0.0080 | loss: 0.3457 | cls_loss: 4.9854 | cnt_loss: 0.3457\n",
      "Eval Epoch: 7 | acc: 0.0070 | loss: 0.3203 | cls_loss: 4.9809 | cnt_loss: 0.3203\n",
      "Eval Epoch: 8 | acc: 0.0010 | loss: 0.2791 | cls_loss: 4.9833 | cnt_loss: 0.2791\n",
      "Eval Epoch: 9 | acc: 0.0050 | loss: 0.2492 | cls_loss: 4.9827 | cnt_loss: 0.2492\n",
      "Eval Epoch: 10 | acc: 0.0030 | loss: 0.2472 | cls_loss: 4.9851 | cnt_loss: 0.2472\n",
      "Eval Epoch: 11 | acc: 0.0040 | loss: 0.2236 | cls_loss: 4.9826 | cnt_loss: 0.2236\n",
      "Eval Epoch: 12 | acc: 0.0030 | loss: 0.2206 | cls_loss: 4.9831 | cnt_loss: 0.2206\n",
      "Eval Epoch: 13 | acc: 0.0020 | loss: 0.2042 | cls_loss: 4.9822 | cnt_loss: 0.2042\n",
      "Eval Epoch: 14 | acc: 0.0010 | loss: 0.2083 | cls_loss: 4.9847 | cnt_loss: 0.2083\n",
      "Eval Epoch: 15 | acc: 0.0010 | loss: 0.2001 | cls_loss: 4.9847 | cnt_loss: 0.2001\n",
      "Eval Epoch: 16 | acc: 0.0030 | loss: 0.2066 | cls_loss: 4.9796 | cnt_loss: 0.2066\n",
      "Eval Epoch: 17 | acc: 0.0010 | loss: 0.1798 | cls_loss: 4.9777 | cnt_loss: 0.1798\n",
      "Eval Epoch: 18 | acc: 0.0010 | loss: 0.1747 | cls_loss: 4.9782 | cnt_loss: 0.1747\n",
      "Eval Epoch: 19 | acc: 0.0010 | loss: 0.1668 | cls_loss: 4.9779 | cnt_loss: 0.1668\n",
      "Eval Epoch: 20 | acc: 0.0030 | loss: 0.1655 | cls_loss: 4.9772 | cnt_loss: 0.1655\n",
      "Eval Epoch: 21 | acc: 0.0030 | loss: 0.1737 | cls_loss: 4.9760 | cnt_loss: 0.1737\n",
      "Eval Epoch: 22 | acc: 0.0020 | loss: 0.1817 | cls_loss: 4.9743 | cnt_loss: 0.1817\n",
      "Eval Epoch: 23 | acc: 0.0010 | loss: 0.1571 | cls_loss: 4.9749 | cnt_loss: 0.1571\n",
      "Eval Epoch: 24 | acc: 0.0000 | loss: 0.1633 | cls_loss: 4.9713 | cnt_loss: 0.1633\n",
      "Eval Epoch: 25 | acc: 0.0000 | loss: 0.1571 | cls_loss: 4.9710 | cnt_loss: 0.1571\n",
      "Eval Epoch: 26 | acc: 0.0000 | loss: 0.1504 | cls_loss: 4.9697 | cnt_loss: 0.1504\n",
      "Eval Epoch: 27 | acc: 0.0000 | loss: 0.1493 | cls_loss: 4.9741 | cnt_loss: 0.1493\n",
      "Eval Epoch: 28 | acc: 0.0000 | loss: 0.1508 | cls_loss: 4.9676 | cnt_loss: 0.1508\n",
      "Eval Epoch: 29 | acc: 0.0010 | loss: 0.1472 | cls_loss: 4.9714 | cnt_loss: 0.1472\n",
      "Eval Epoch: 30 | acc: 0.0020 | loss: 0.1594 | cls_loss: 4.9711 | cnt_loss: 0.1594\n",
      "Eval Epoch: 31 | acc: 0.0000 | loss: 0.1417 | cls_loss: 4.9712 | cnt_loss: 0.1417\n",
      "Eval Epoch: 32 | acc: 0.0010 | loss: 0.1500 | cls_loss: 4.9670 | cnt_loss: 0.1500\n",
      "Eval Epoch: 33 | acc: 0.0020 | loss: 0.1441 | cls_loss: 4.9680 | cnt_loss: 0.1441\n",
      "Eval Epoch: 34 | acc: 0.0020 | loss: 0.1517 | cls_loss: 4.9702 | cnt_loss: 0.1517\n",
      "Eval Epoch: 35 | acc: 0.0010 | loss: 0.1541 | cls_loss: 4.9680 | cnt_loss: 0.1541\n",
      "Eval Epoch: 36 | acc: 0.0010 | loss: 0.1461 | cls_loss: 4.9696 | cnt_loss: 0.1461\n",
      "Eval Epoch: 37 | acc: 0.0020 | loss: 0.1512 | cls_loss: 4.9683 | cnt_loss: 0.1512\n",
      "Eval Epoch: 38 | acc: 0.0020 | loss: 0.1526 | cls_loss: 4.9681 | cnt_loss: 0.1526\n",
      "Eval Epoch: 39 | acc: 0.0020 | loss: 0.1575 | cls_loss: 4.9671 | cnt_loss: 0.1575\n",
      "Eval Epoch: 40 | acc: 0.0030 | loss: 0.1439 | cls_loss: 4.9653 | cnt_loss: 0.1439\n",
      "Eval Epoch: 41 | acc: 0.0010 | loss: 0.1391 | cls_loss: 4.9643 | cnt_loss: 0.1391\n",
      "Eval Epoch: 42 | acc: 0.0020 | loss: 0.1378 | cls_loss: 4.9650 | cnt_loss: 0.1378\n",
      "Eval Epoch: 43 | acc: 0.0010 | loss: 0.1494 | cls_loss: 4.9638 | cnt_loss: 0.1494\n",
      "Eval Epoch: 44 | acc: 0.0010 | loss: 0.1476 | cls_loss: 4.9620 | cnt_loss: 0.1476\n",
      "Eval Epoch: 45 | acc: 0.0020 | loss: 0.1422 | cls_loss: 4.9605 | cnt_loss: 0.1422\n",
      "Eval Epoch: 46 | acc: 0.0010 | loss: 0.1486 | cls_loss: 4.9604 | cnt_loss: 0.1486\n",
      "Eval Epoch: 47 | acc: 0.0010 | loss: 0.1577 | cls_loss: 4.9652 | cnt_loss: 0.1577\n",
      "Eval Epoch: 48 | acc: 0.0010 | loss: 0.1392 | cls_loss: 4.9628 | cnt_loss: 0.1392\n",
      "Eval Epoch: 49 | acc: 0.0000 | loss: 0.1383 | cls_loss: 4.9623 | cnt_loss: 0.1383\n",
      "Eval Epoch: 50 | acc: 0.0000 | loss: 0.1392 | cls_loss: 4.9625 | cnt_loss: 0.1392\n",
      "Eval Epoch: 51 | acc: 0.0000 | loss: 0.1345 | cls_loss: 4.9636 | cnt_loss: 0.1345\n",
      "Eval Epoch: 52 | acc: 0.0010 | loss: 0.1383 | cls_loss: 4.9615 | cnt_loss: 0.1383\n",
      "Eval Epoch: 53 | acc: 0.0020 | loss: 0.1370 | cls_loss: 4.9613 | cnt_loss: 0.1370\n",
      "Eval Epoch: 54 | acc: 0.0010 | loss: 0.1360 | cls_loss: 4.9620 | cnt_loss: 0.1360\n",
      "Eval Epoch: 55 | acc: 0.0000 | loss: 0.1428 | cls_loss: 4.9625 | cnt_loss: 0.1428\n",
      "Eval Epoch: 56 | acc: 0.0000 | loss: 0.1376 | cls_loss: 4.9621 | cnt_loss: 0.1376\n",
      "Eval Epoch: 57 | acc: 0.0000 | loss: 0.1432 | cls_loss: 4.9599 | cnt_loss: 0.1432\n",
      "Eval Epoch: 58 | acc: 0.0010 | loss: 0.1372 | cls_loss: 4.9622 | cnt_loss: 0.1372\n",
      "Eval Epoch: 59 | acc: 0.0000 | loss: 0.1329 | cls_loss: 4.9596 | cnt_loss: 0.1329\n",
      "Eval Epoch: 60 | acc: 0.0010 | loss: 0.1475 | cls_loss: 4.9576 | cnt_loss: 0.1475\n",
      "Eval Epoch: 61 | acc: 0.0010 | loss: 0.1403 | cls_loss: 4.9606 | cnt_loss: 0.1403\n",
      "Eval Epoch: 62 | acc: 0.0010 | loss: 0.1442 | cls_loss: 4.9606 | cnt_loss: 0.1442\n",
      "Eval Epoch: 63 | acc: 0.0010 | loss: 0.1452 | cls_loss: 4.9593 | cnt_loss: 0.1452\n",
      "Eval Epoch: 64 | acc: 0.0010 | loss: 0.1386 | cls_loss: 4.9607 | cnt_loss: 0.1386\n",
      "Eval Epoch: 65 | acc: 0.0010 | loss: 0.1407 | cls_loss: 4.9603 | cnt_loss: 0.1407\n",
      "Eval Epoch: 66 | acc: 0.0000 | loss: 0.1393 | cls_loss: 4.9600 | cnt_loss: 0.1393\n",
      "Eval Epoch: 67 | acc: 0.0010 | loss: 0.1341 | cls_loss: 4.9597 | cnt_loss: 0.1341\n",
      "Eval Epoch: 68 | acc: 0.0000 | loss: 0.1559 | cls_loss: 4.9617 | cnt_loss: 0.1559\n",
      "Eval Epoch: 69 | acc: 0.0010 | loss: 0.1372 | cls_loss: 4.9574 | cnt_loss: 0.1372\n",
      "Early stop at epoch 69. Best val loss: 0.1329, with acc: 0.0000, after epoch: 59\n",
      "Top-1 accuracy: 0.0\n",
      "Macro F1:0.0\n",
      "Per-pair accuracy: 0.023\n",
      "RMSE per class: [0.49303746223449707, 0.5188505053520203, 0.5679834485054016, 0.5762630105018616, 0.59776371717453, 0.5692645907402039]\n",
      "MAE per class: [0.27286794781684875, 0.28720545768737793, 0.33015206456184387, 0.31675031781196594, 0.3304028809070587, 0.32325491309165955]\n",
      "Overall RMSE: 0.5550314784049988\n",
      "Overall MAE: 0.3101056218147278\n",
      "Saved model to models/model_reg_only.pt\n",
      "\n",
      "=== Training mode=multitask, lambda_cnt=0.3 ===\n",
      "Eval Epoch: 1 | acc: 0.0110 | loss: 5.1056 | cls_loss: 4.6806 | cnt_loss: 1.4168\n",
      "Eval Epoch: 2 | acc: 0.0260 | loss: 4.5540 | cls_loss: 4.1831 | cnt_loss: 1.2361\n",
      "Eval Epoch: 3 | acc: 0.1000 | loss: 3.3136 | cls_loss: 3.0304 | cnt_loss: 0.9440\n",
      "Eval Epoch: 4 | acc: 0.1230 | loss: 2.9846 | cls_loss: 2.7243 | cnt_loss: 0.8675\n",
      "Eval Epoch: 5 | acc: 0.1690 | loss: 2.7956 | cls_loss: 2.5743 | cnt_loss: 0.7378\n",
      "Eval Epoch: 6 | acc: 0.2190 | loss: 2.4582 | cls_loss: 2.3042 | cnt_loss: 0.5135\n",
      "Eval Epoch: 7 | acc: 0.3150 | loss: 1.9486 | cls_loss: 1.8375 | cnt_loss: 0.3702\n",
      "Eval Epoch: 8 | acc: 0.3370 | loss: 1.7998 | cls_loss: 1.7033 | cnt_loss: 0.3218\n",
      "Eval Epoch: 9 | acc: 0.3410 | loss: 1.6609 | cls_loss: 1.5790 | cnt_loss: 0.2730\n",
      "Eval Epoch: 10 | acc: 0.3890 | loss: 1.5613 | cls_loss: 1.4833 | cnt_loss: 0.2600\n",
      "Eval Epoch: 11 | acc: 0.3880 | loss: 1.5575 | cls_loss: 1.4853 | cnt_loss: 0.2407\n",
      "Eval Epoch: 12 | acc: 0.4090 | loss: 1.5362 | cls_loss: 1.4651 | cnt_loss: 0.2371\n",
      "Eval Epoch: 13 | acc: 0.4250 | loss: 1.4893 | cls_loss: 1.4181 | cnt_loss: 0.2374\n",
      "Eval Epoch: 14 | acc: 0.4410 | loss: 1.4124 | cls_loss: 1.3495 | cnt_loss: 0.2096\n",
      "Eval Epoch: 15 | acc: 0.3720 | loss: 1.5953 | cls_loss: 1.5260 | cnt_loss: 0.2311\n",
      "Eval Epoch: 16 | acc: 0.4290 | loss: 1.4284 | cls_loss: 1.3679 | cnt_loss: 0.2015\n",
      "Eval Epoch: 17 | acc: 0.4440 | loss: 1.4315 | cls_loss: 1.3732 | cnt_loss: 0.1945\n",
      "Eval Epoch: 18 | acc: 0.4660 | loss: 1.3688 | cls_loss: 1.3121 | cnt_loss: 0.1889\n",
      "Eval Epoch: 19 | acc: 0.4620 | loss: 1.3673 | cls_loss: 1.3119 | cnt_loss: 0.1850\n",
      "Eval Epoch: 20 | acc: 0.4640 | loss: 1.3517 | cls_loss: 1.2961 | cnt_loss: 0.1852\n",
      "Eval Epoch: 21 | acc: 0.4890 | loss: 1.2921 | cls_loss: 1.2388 | cnt_loss: 0.1776\n",
      "Eval Epoch: 22 | acc: 0.5070 | loss: 1.2867 | cls_loss: 1.2342 | cnt_loss: 0.1751\n",
      "Eval Epoch: 23 | acc: 0.4840 | loss: 1.2791 | cls_loss: 1.2305 | cnt_loss: 0.1620\n",
      "Eval Epoch: 24 | acc: 0.4850 | loss: 1.3239 | cls_loss: 1.2711 | cnt_loss: 0.1761\n",
      "Eval Epoch: 25 | acc: 0.5010 | loss: 1.2499 | cls_loss: 1.2037 | cnt_loss: 0.1542\n",
      "Eval Epoch: 26 | acc: 0.4860 | loss: 1.3367 | cls_loss: 1.2863 | cnt_loss: 0.1677\n",
      "Eval Epoch: 27 | acc: 0.4930 | loss: 1.2726 | cls_loss: 1.2251 | cnt_loss: 0.1582\n",
      "Eval Epoch: 28 | acc: 0.5130 | loss: 1.2807 | cls_loss: 1.2328 | cnt_loss: 0.1596\n",
      "Eval Epoch: 29 | acc: 0.4690 | loss: 1.3663 | cls_loss: 1.3116 | cnt_loss: 0.1825\n",
      "Eval Epoch: 30 | acc: 0.5210 | loss: 1.2248 | cls_loss: 1.1784 | cnt_loss: 0.1549\n",
      "Eval Epoch: 31 | acc: 0.5010 | loss: 1.2424 | cls_loss: 1.1949 | cnt_loss: 0.1585\n",
      "Eval Epoch: 32 | acc: 0.4710 | loss: 1.3661 | cls_loss: 1.3166 | cnt_loss: 0.1650\n",
      "Eval Epoch: 33 | acc: 0.5050 | loss: 1.2975 | cls_loss: 1.2518 | cnt_loss: 0.1522\n",
      "Eval Epoch: 34 | acc: 0.4890 | loss: 1.3321 | cls_loss: 1.2860 | cnt_loss: 0.1537\n",
      "Eval Epoch: 35 | acc: 0.4740 | loss: 1.3131 | cls_loss: 1.2662 | cnt_loss: 0.1564\n",
      "Eval Epoch: 36 | acc: 0.4990 | loss: 1.2574 | cls_loss: 1.2142 | cnt_loss: 0.1438\n",
      "Eval Epoch: 37 | acc: 0.4880 | loss: 1.3364 | cls_loss: 1.2892 | cnt_loss: 0.1573\n",
      "Eval Epoch: 38 | acc: 0.5040 | loss: 1.3019 | cls_loss: 1.2564 | cnt_loss: 0.1517\n",
      "Eval Epoch: 39 | acc: 0.4950 | loss: 1.2952 | cls_loss: 1.2499 | cnt_loss: 0.1509\n",
      "Eval Epoch: 40 | acc: 0.5100 | loss: 1.2902 | cls_loss: 1.2434 | cnt_loss: 0.1558\n",
      "Early stop at epoch 40. Best val loss: 1.2248, with acc: 0.5210, after epoch: 30\n",
      "Top-1 accuracy: 0.5210000276565552\n",
      "Macro F1:0.5001977216209628\n",
      "Per-pair accuracy: 0.953\n",
      "RMSE per class: [0.5626434087753296, 0.5422553420066833, 0.6271865963935852, 0.6286020278930664, 0.5878118276596069, 0.6635043621063232]\n",
      "MAE per class: [0.3303215503692627, 0.3346816897392273, 0.3768671751022339, 0.38134998083114624, 0.3539736270904541, 0.397741436958313]\n",
      "Overall RMSE: 0.6034446954727173\n",
      "Overall MAE: 0.362489253282547\n",
      "Saved model to models/model_multitask_lambda0_3.pt\n",
      "\n",
      "=== Training mode=multitask, lambda_cnt=0.5 ===\n",
      "Eval Epoch: 1 | acc: 0.0090 | loss: 5.3810 | cls_loss: 4.6746 | cnt_loss: 1.4128\n",
      "Eval Epoch: 2 | acc: 0.0340 | loss: 4.5455 | cls_loss: 3.9180 | cnt_loss: 1.2551\n",
      "Eval Epoch: 3 | acc: 0.0890 | loss: 3.9567 | cls_loss: 3.4255 | cnt_loss: 1.0623\n",
      "Eval Epoch: 4 | acc: 0.1650 | loss: 2.9054 | cls_loss: 2.5787 | cnt_loss: 0.6533\n",
      "Eval Epoch: 5 | acc: 0.2050 | loss: 2.5520 | cls_loss: 2.2973 | cnt_loss: 0.5093\n",
      "Eval Epoch: 6 | acc: 0.2880 | loss: 2.1234 | cls_loss: 1.9363 | cnt_loss: 0.3742\n",
      "Eval Epoch: 7 | acc: 0.2730 | loss: 2.0408 | cls_loss: 1.8629 | cnt_loss: 0.3557\n",
      "Eval Epoch: 8 | acc: 0.2920 | loss: 1.9853 | cls_loss: 1.8271 | cnt_loss: 0.3163\n",
      "Eval Epoch: 9 | acc: 0.3560 | loss: 1.8340 | cls_loss: 1.6897 | cnt_loss: 0.2885\n",
      "Eval Epoch: 10 | acc: 0.3320 | loss: 1.7970 | cls_loss: 1.6594 | cnt_loss: 0.2752\n",
      "Eval Epoch: 11 | acc: 0.3720 | loss: 1.7332 | cls_loss: 1.6021 | cnt_loss: 0.2623\n",
      "Eval Epoch: 12 | acc: 0.3790 | loss: 1.6607 | cls_loss: 1.5394 | cnt_loss: 0.2425\n",
      "Eval Epoch: 13 | acc: 0.3660 | loss: 1.6126 | cls_loss: 1.5069 | cnt_loss: 0.2114\n",
      "Eval Epoch: 14 | acc: 0.4030 | loss: 1.5494 | cls_loss: 1.4428 | cnt_loss: 0.2131\n",
      "Eval Epoch: 15 | acc: 0.3990 | loss: 1.5330 | cls_loss: 1.4316 | cnt_loss: 0.2028\n",
      "Eval Epoch: 16 | acc: 0.4350 | loss: 1.4771 | cls_loss: 1.3758 | cnt_loss: 0.2027\n",
      "Eval Epoch: 17 | acc: 0.3890 | loss: 1.6268 | cls_loss: 1.5178 | cnt_loss: 0.2181\n",
      "Eval Epoch: 18 | acc: 0.3970 | loss: 1.5316 | cls_loss: 1.4301 | cnt_loss: 0.2029\n",
      "Eval Epoch: 19 | acc: 0.4350 | loss: 1.4644 | cls_loss: 1.3684 | cnt_loss: 0.1920\n",
      "Eval Epoch: 20 | acc: 0.4400 | loss: 1.4426 | cls_loss: 1.3525 | cnt_loss: 0.1802\n",
      "Eval Epoch: 21 | acc: 0.4340 | loss: 1.4044 | cls_loss: 1.3170 | cnt_loss: 0.1747\n",
      "Eval Epoch: 22 | acc: 0.4520 | loss: 1.3818 | cls_loss: 1.2939 | cnt_loss: 0.1759\n",
      "Eval Epoch: 23 | acc: 0.5020 | loss: 1.3398 | cls_loss: 1.2546 | cnt_loss: 0.1704\n",
      "Eval Epoch: 24 | acc: 0.4410 | loss: 1.4139 | cls_loss: 1.3293 | cnt_loss: 0.1691\n",
      "Eval Epoch: 25 | acc: 0.4290 | loss: 1.4198 | cls_loss: 1.3340 | cnt_loss: 0.1716\n",
      "Eval Epoch: 26 | acc: 0.4250 | loss: 1.4194 | cls_loss: 1.3340 | cnt_loss: 0.1708\n",
      "Eval Epoch: 27 | acc: 0.4620 | loss: 1.3400 | cls_loss: 1.2618 | cnt_loss: 0.1564\n",
      "Eval Epoch: 28 | acc: 0.4660 | loss: 1.3270 | cls_loss: 1.2501 | cnt_loss: 0.1537\n",
      "Eval Epoch: 29 | acc: 0.4780 | loss: 1.3156 | cls_loss: 1.2388 | cnt_loss: 0.1538\n",
      "Eval Epoch: 30 | acc: 0.4640 | loss: 1.3321 | cls_loss: 1.2571 | cnt_loss: 0.1500\n",
      "Eval Epoch: 31 | acc: 0.4680 | loss: 1.3392 | cls_loss: 1.2624 | cnt_loss: 0.1536\n",
      "Eval Epoch: 32 | acc: 0.4980 | loss: 1.2812 | cls_loss: 1.2100 | cnt_loss: 0.1424\n",
      "Eval Epoch: 33 | acc: 0.4640 | loss: 1.3340 | cls_loss: 1.2600 | cnt_loss: 0.1479\n",
      "Eval Epoch: 34 | acc: 0.5140 | loss: 1.2523 | cls_loss: 1.1792 | cnt_loss: 0.1461\n",
      "Eval Epoch: 35 | acc: 0.5110 | loss: 1.2376 | cls_loss: 1.1675 | cnt_loss: 0.1402\n",
      "Eval Epoch: 36 | acc: 0.5090 | loss: 1.2964 | cls_loss: 1.2245 | cnt_loss: 0.1437\n",
      "Eval Epoch: 37 | acc: 0.5130 | loss: 1.2425 | cls_loss: 1.1731 | cnt_loss: 0.1388\n",
      "Eval Epoch: 38 | acc: 0.5110 | loss: 1.3135 | cls_loss: 1.2402 | cnt_loss: 0.1466\n",
      "Eval Epoch: 39 | acc: 0.5140 | loss: 1.2316 | cls_loss: 1.1651 | cnt_loss: 0.1330\n",
      "Eval Epoch: 40 | acc: 0.5080 | loss: 1.2989 | cls_loss: 1.2284 | cnt_loss: 0.1411\n",
      "Eval Epoch: 41 | acc: 0.4950 | loss: 1.3322 | cls_loss: 1.2591 | cnt_loss: 0.1462\n",
      "Eval Epoch: 42 | acc: 0.5130 | loss: 1.2630 | cls_loss: 1.1929 | cnt_loss: 0.1401\n",
      "Eval Epoch: 43 | acc: 0.5170 | loss: 1.2834 | cls_loss: 1.2152 | cnt_loss: 0.1364\n",
      "Eval Epoch: 44 | acc: 0.5010 | loss: 1.3004 | cls_loss: 1.2323 | cnt_loss: 0.1362\n",
      "Eval Epoch: 45 | acc: 0.4940 | loss: 1.3057 | cls_loss: 1.2388 | cnt_loss: 0.1338\n",
      "Eval Epoch: 46 | acc: 0.4950 | loss: 1.3049 | cls_loss: 1.2371 | cnt_loss: 0.1356\n",
      "Eval Epoch: 47 | acc: 0.5190 | loss: 1.2763 | cls_loss: 1.2101 | cnt_loss: 0.1324\n",
      "Eval Epoch: 48 | acc: 0.5040 | loss: 1.2719 | cls_loss: 1.2063 | cnt_loss: 0.1313\n",
      "Eval Epoch: 49 | acc: 0.5060 | loss: 1.3485 | cls_loss: 1.2822 | cnt_loss: 0.1326\n",
      "Early stop at epoch 49. Best val loss: 1.2316, with acc: 0.5140, after epoch: 39\n",
      "Top-1 accuracy: 0.5139999985694885\n",
      "Macro F1:0.47920870414535816\n",
      "Per-pair accuracy: 0.952\n",
      "RMSE per class: [0.4578821063041687, 0.48316025733947754, 0.5726819634437561, 0.6212713718414307, 0.5431850552558899, 0.6383643746376038]\n",
      "MAE per class: [0.281477689743042, 0.29874199628829956, 0.3659662902355194, 0.3448461890220642, 0.3268200755119324, 0.37309974431991577]\n",
      "Overall RMSE: 0.556716799736023\n",
      "Overall MAE: 0.3318253457546234\n",
      "Saved model to models/model_multitask_lambda0_5.pt\n",
      "\n",
      "=== Training mode=multitask, lambda_cnt=1.0 ===\n",
      "Eval Epoch: 1 | acc: 0.0050 | loss: 6.1003 | cls_loss: 4.6820 | cnt_loss: 1.4183\n",
      "Eval Epoch: 2 | acc: 0.0180 | loss: 5.9099 | cls_loss: 4.5462 | cnt_loss: 1.3637\n",
      "Eval Epoch: 3 | acc: 0.0350 | loss: 5.0269 | cls_loss: 3.8108 | cnt_loss: 1.2161\n",
      "Eval Epoch: 4 | acc: 0.0910 | loss: 4.1336 | cls_loss: 3.2486 | cnt_loss: 0.8850\n",
      "Eval Epoch: 5 | acc: 0.2510 | loss: 2.6747 | cls_loss: 2.2285 | cnt_loss: 0.4462\n",
      "Eval Epoch: 6 | acc: 0.2570 | loss: 2.2551 | cls_loss: 1.9355 | cnt_loss: 0.3196\n",
      "Eval Epoch: 7 | acc: 0.2970 | loss: 2.0476 | cls_loss: 1.7636 | cnt_loss: 0.2840\n",
      "Eval Epoch: 8 | acc: 0.3570 | loss: 1.8986 | cls_loss: 1.6449 | cnt_loss: 0.2538\n",
      "Eval Epoch: 9 | acc: 0.3730 | loss: 1.8111 | cls_loss: 1.5706 | cnt_loss: 0.2404\n",
      "Eval Epoch: 10 | acc: 0.3930 | loss: 1.6808 | cls_loss: 1.4696 | cnt_loss: 0.2111\n",
      "Eval Epoch: 11 | acc: 0.3830 | loss: 1.6925 | cls_loss: 1.4904 | cnt_loss: 0.2020\n",
      "Eval Epoch: 12 | acc: 0.3910 | loss: 1.6228 | cls_loss: 1.4369 | cnt_loss: 0.1859\n",
      "Eval Epoch: 13 | acc: 0.4000 | loss: 1.5640 | cls_loss: 1.3843 | cnt_loss: 0.1796\n",
      "Eval Epoch: 14 | acc: 0.4160 | loss: 1.5507 | cls_loss: 1.3672 | cnt_loss: 0.1834\n",
      "Eval Epoch: 15 | acc: 0.4280 | loss: 1.5385 | cls_loss: 1.3562 | cnt_loss: 0.1822\n",
      "Eval Epoch: 16 | acc: 0.4300 | loss: 1.5164 | cls_loss: 1.3480 | cnt_loss: 0.1684\n",
      "Eval Epoch: 17 | acc: 0.4370 | loss: 1.5174 | cls_loss: 1.3481 | cnt_loss: 0.1693\n",
      "Eval Epoch: 18 | acc: 0.4540 | loss: 1.5134 | cls_loss: 1.3360 | cnt_loss: 0.1773\n",
      "Eval Epoch: 19 | acc: 0.4290 | loss: 1.5072 | cls_loss: 1.3252 | cnt_loss: 0.1820\n",
      "Eval Epoch: 20 | acc: 0.4390 | loss: 1.5255 | cls_loss: 1.3418 | cnt_loss: 0.1837\n",
      "Eval Epoch: 21 | acc: 0.4540 | loss: 1.4210 | cls_loss: 1.2686 | cnt_loss: 0.1524\n",
      "Eval Epoch: 22 | acc: 0.4540 | loss: 1.4709 | cls_loss: 1.3003 | cnt_loss: 0.1706\n",
      "Eval Epoch: 23 | acc: 0.4850 | loss: 1.4015 | cls_loss: 1.2500 | cnt_loss: 0.1515\n",
      "Eval Epoch: 24 | acc: 0.4590 | loss: 1.4211 | cls_loss: 1.2700 | cnt_loss: 0.1512\n",
      "Eval Epoch: 25 | acc: 0.4550 | loss: 1.4218 | cls_loss: 1.2689 | cnt_loss: 0.1529\n",
      "Eval Epoch: 26 | acc: 0.4500 | loss: 1.4374 | cls_loss: 1.2849 | cnt_loss: 0.1525\n",
      "Eval Epoch: 27 | acc: 0.4670 | loss: 1.4120 | cls_loss: 1.2632 | cnt_loss: 0.1487\n",
      "Eval Epoch: 28 | acc: 0.4710 | loss: 1.4249 | cls_loss: 1.2725 | cnt_loss: 0.1523\n",
      "Eval Epoch: 29 | acc: 0.4770 | loss: 1.4123 | cls_loss: 1.2656 | cnt_loss: 0.1466\n",
      "Eval Epoch: 30 | acc: 0.4820 | loss: 1.3759 | cls_loss: 1.2305 | cnt_loss: 0.1453\n",
      "Eval Epoch: 31 | acc: 0.4800 | loss: 1.4042 | cls_loss: 1.2637 | cnt_loss: 0.1405\n",
      "Eval Epoch: 32 | acc: 0.4760 | loss: 1.4299 | cls_loss: 1.2808 | cnt_loss: 0.1492\n",
      "Eval Epoch: 33 | acc: 0.4800 | loss: 1.4161 | cls_loss: 1.2668 | cnt_loss: 0.1492\n",
      "Eval Epoch: 34 | acc: 0.4840 | loss: 1.3713 | cls_loss: 1.2348 | cnt_loss: 0.1364\n",
      "Eval Epoch: 35 | acc: 0.4700 | loss: 1.5289 | cls_loss: 1.3679 | cnt_loss: 0.1611\n",
      "Eval Epoch: 36 | acc: 0.4820 | loss: 1.3964 | cls_loss: 1.2530 | cnt_loss: 0.1433\n",
      "Eval Epoch: 37 | acc: 0.4800 | loss: 1.4485 | cls_loss: 1.3044 | cnt_loss: 0.1442\n",
      "Eval Epoch: 38 | acc: 0.5110 | loss: 1.3892 | cls_loss: 1.2477 | cnt_loss: 0.1415\n",
      "Eval Epoch: 39 | acc: 0.4850 | loss: 1.4365 | cls_loss: 1.2891 | cnt_loss: 0.1473\n",
      "Eval Epoch: 40 | acc: 0.4670 | loss: 1.5327 | cls_loss: 1.3755 | cnt_loss: 0.1572\n",
      "Eval Epoch: 41 | acc: 0.5060 | loss: 1.3792 | cls_loss: 1.2515 | cnt_loss: 0.1277\n",
      "Eval Epoch: 42 | acc: 0.4860 | loss: 1.4596 | cls_loss: 1.3229 | cnt_loss: 0.1367\n",
      "Eval Epoch: 43 | acc: 0.5000 | loss: 1.4314 | cls_loss: 1.2844 | cnt_loss: 0.1469\n",
      "Eval Epoch: 44 | acc: 0.4760 | loss: 1.4276 | cls_loss: 1.2887 | cnt_loss: 0.1389\n",
      "Early stop at epoch 44. Best val loss: 1.3713, with acc: 0.4840, after epoch: 34\n",
      "Top-1 accuracy: 0.48399999737739563\n",
      "Macro F1:0.4518037611892341\n",
      "Per-pair accuracy: 0.947\n",
      "RMSE per class: [0.46826133131980896, 0.4819292426109314, 0.5908148884773254, 0.605099081993103, 0.5845974087715149, 0.6431415677070618]\n",
      "MAE per class: [0.27131927013397217, 0.2920176386833191, 0.3304550349712372, 0.3383287489414215, 0.32832419872283936, 0.3672081232070923]\n",
      "Overall RMSE: 0.5659971833229065\n",
      "Overall MAE: 0.3212755024433136\n",
      "Saved model to models/model_multitask_lambda1_0.pt\n",
      "\n",
      "Saved all results dict to models/results.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cls_only': {'history': {'train_loss': [4.727255440606012,\n",
       "    4.67275235748291,\n",
       "    4.222638869815403,\n",
       "    3.3035047062767875,\n",
       "    2.7288177575005426,\n",
       "    2.3264633657667373,\n",
       "    2.0876981253094145,\n",
       "    1.9049107961654663,\n",
       "    1.734792820294698,\n",
       "    1.6766099809010824,\n",
       "    1.6101154088974,\n",
       "    1.5339518444273208,\n",
       "    1.4821877431869508,\n",
       "    1.4662117142147488,\n",
       "    1.409798386891683,\n",
       "    1.3554782410727606,\n",
       "    1.3567470243242052,\n",
       "    1.309702552901374,\n",
       "    1.2928551042344836,\n",
       "    1.2640149385664199,\n",
       "    1.241083093855116,\n",
       "    1.217800605032179,\n",
       "    1.2073084926605224,\n",
       "    1.181831755426195,\n",
       "    1.142301187409295,\n",
       "    1.1054777488178678,\n",
       "    1.1021307236353557,\n",
       "    1.0888401051627266,\n",
       "    1.0770724494722155,\n",
       "    1.0430111405054727,\n",
       "    1.008509994453854,\n",
       "    1.0139290359285142,\n",
       "    1.0060970865885417,\n",
       "    0.9810530780686273,\n",
       "    0.9702429509692722,\n",
       "    0.9447353371514214,\n",
       "    0.9354657807879978,\n",
       "    0.9037643768522474,\n",
       "    0.8888993995984396,\n",
       "    0.9066486066182454,\n",
       "    0.8734976245032416,\n",
       "    0.842687353875902,\n",
       "    0.8119417368570964,\n",
       "    0.8082262028588189,\n",
       "    0.7883770928912692,\n",
       "    0.7737213839424981,\n",
       "    0.7650566154056125],\n",
       "   'eval_loss': [4.6752777099609375,\n",
       "    4.620830535888672,\n",
       "    3.6989998817443848,\n",
       "    2.8056957721710205,\n",
       "    2.3039422035217285,\n",
       "    2.1355464458465576,\n",
       "    1.801873803138733,\n",
       "    1.683071255683899,\n",
       "    1.5597468614578247,\n",
       "    1.5707478523254395,\n",
       "    1.5218095779418945,\n",
       "    1.4729578495025635,\n",
       "    1.4260085821151733,\n",
       "    1.4101800918579102,\n",
       "    1.3850584030151367,\n",
       "    1.3322066068649292,\n",
       "    1.4085386991500854,\n",
       "    1.3308312892913818,\n",
       "    1.2902487516403198,\n",
       "    1.3041677474975586,\n",
       "    1.4306596517562866,\n",
       "    1.3368064165115356,\n",
       "    1.2826263904571533,\n",
       "    1.2290968894958496,\n",
       "    1.2543631792068481,\n",
       "    1.2490110397338867,\n",
       "    1.474684715270996,\n",
       "    1.2788536548614502,\n",
       "    1.2229598760604858,\n",
       "    1.2271913290023804,\n",
       "    1.2263052463531494,\n",
       "    1.2655409574508667,\n",
       "    1.2219352722167969,\n",
       "    1.2729061841964722,\n",
       "    1.2942196130752563,\n",
       "    1.2844079732894897,\n",
       "    1.194259762763977,\n",
       "    1.301714301109314,\n",
       "    1.3685981035232544,\n",
       "    1.3982123136520386,\n",
       "    1.2235878705978394,\n",
       "    1.2662255764007568,\n",
       "    1.2854907512664795,\n",
       "    1.297406792640686,\n",
       "    1.3144036531448364,\n",
       "    1.2916395664215088,\n",
       "    1.3184818029403687],\n",
       "   'eval_acc': [0.005,\n",
       "    0.013,\n",
       "    0.062,\n",
       "    0.142,\n",
       "    0.224,\n",
       "    0.236,\n",
       "    0.311,\n",
       "    0.348,\n",
       "    0.379,\n",
       "    0.354,\n",
       "    0.369,\n",
       "    0.387,\n",
       "    0.419,\n",
       "    0.382,\n",
       "    0.423,\n",
       "    0.448,\n",
       "    0.426,\n",
       "    0.447,\n",
       "    0.44,\n",
       "    0.443,\n",
       "    0.392,\n",
       "    0.45,\n",
       "    0.465,\n",
       "    0.485,\n",
       "    0.449,\n",
       "    0.481,\n",
       "    0.408,\n",
       "    0.463,\n",
       "    0.484,\n",
       "    0.498,\n",
       "    0.484,\n",
       "    0.474,\n",
       "    0.493,\n",
       "    0.503,\n",
       "    0.49,\n",
       "    0.498,\n",
       "    0.512,\n",
       "    0.49,\n",
       "    0.477,\n",
       "    0.46,\n",
       "    0.522,\n",
       "    0.521,\n",
       "    0.505,\n",
       "    0.518,\n",
       "    0.526,\n",
       "    0.542,\n",
       "    0.516],\n",
       "   'eval_rmse': [3.092585428960155,\n",
       "    3.1079745589973866,\n",
       "    3.1593928247106806,\n",
       "    3.2002872592419993,\n",
       "    3.2016960227159292,\n",
       "    3.217138350563536,\n",
       "    3.2218902561876104,\n",
       "    3.2303224410136937,\n",
       "    3.22492086466216,\n",
       "    3.216205001142651,\n",
       "    3.2384767670670933,\n",
       "    3.2325301703283964,\n",
       "    3.2255352228674132,\n",
       "    3.2248574742407867,\n",
       "    3.2269010869563384,\n",
       "    3.241876064359442,\n",
       "    3.23477322427709,\n",
       "    3.224272770072863,\n",
       "    3.2358562429440525,\n",
       "    3.240194643555384,\n",
       "    3.2316802381204632,\n",
       "    3.226546786684902,\n",
       "    3.230611639070843,\n",
       "    3.2312851585772595,\n",
       "    3.2218502464293195,\n",
       "    3.222256585065814,\n",
       "    3.2367092020033765,\n",
       "    3.228315277548028,\n",
       "    3.2293841324624113,\n",
       "    3.236583686286102,\n",
       "    3.237914830244407,\n",
       "    3.2386722660490057,\n",
       "    3.2361409229075093,\n",
       "    3.243677945570943,\n",
       "    3.229241396984747,\n",
       "    3.2367247905547463,\n",
       "    3.2271114091203916,\n",
       "    3.236036509631291,\n",
       "    3.239992404504986,\n",
       "    3.2222151655214875,\n",
       "    3.230518836522239,\n",
       "    3.2401160802572595,\n",
       "    3.2349198413883973,\n",
       "    3.2315538219510853,\n",
       "    3.2328417259432913,\n",
       "    3.243755419070618,\n",
       "    3.2398479259578425]},\n",
       "  'metrics': {'acc': 0.5120000243186951,\n",
       "   'macro_f1': 0.48415950272499025,\n",
       "   'pair_acc': 0.943,\n",
       "   'rmse_per_class': [3.232229709625244,\n",
       "    3.231872081756592,\n",
       "    3.081488847732544,\n",
       "    3.2640373706817627,\n",
       "    3.351954221725464,\n",
       "    3.19500732421875],\n",
       "   'mae_per_class': [1.8422293663024902,\n",
       "    1.9299571514129639,\n",
       "    1.9322302341461182,\n",
       "    2.0161125659942627,\n",
       "    2.0927350521087646,\n",
       "    1.992254376411438],\n",
       "   'overall_rmse': 3.227111339569092,\n",
       "   'overall_mae': 1.967586636543274,\n",
       "   'confusion_matrix': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 6, 0, ..., 0, 0, 0],\n",
       "          [0, 2, 4, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 8, 0, 0],\n",
       "          [0, 0, 0, ..., 4, 8, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], shape=(135, 135))}},\n",
       " 'reg_only': {'history': {'train_loss': [1.3603426560295953,\n",
       "    1.104545012421078,\n",
       "    0.8454983695348104,\n",
       "    0.6843558797836303,\n",
       "    0.5050376942422655,\n",
       "    0.3797633383803897,\n",
       "    0.3075400408903758,\n",
       "    0.2809320397906833,\n",
       "    0.2537829204930199,\n",
       "    0.23750234076711865,\n",
       "    0.2216705141597324,\n",
       "    0.20698612358835008,\n",
       "    0.20116798611481984,\n",
       "    0.18532552075386047,\n",
       "    0.18146063053607941,\n",
       "    0.1734813016520606,\n",
       "    0.16494073952568902,\n",
       "    0.16065642458862728,\n",
       "    0.14688521695137025,\n",
       "    0.1459735065433714,\n",
       "    0.14293505642149185,\n",
       "    0.14159897281726203,\n",
       "    0.13385821892817815,\n",
       "    0.13290076683627233,\n",
       "    0.12592742875549529,\n",
       "    0.12321352879868613,\n",
       "    0.1152628426750501,\n",
       "    0.11764693562189737,\n",
       "    0.11433268280824026,\n",
       "    0.10892616954776976,\n",
       "    0.10682280278205872,\n",
       "    0.10345063388347625,\n",
       "    0.0992182077103191,\n",
       "    0.09963494544559055,\n",
       "    0.09285832775301403,\n",
       "    0.09238384655449125,\n",
       "    0.08878568934069739,\n",
       "    0.08601116575797399,\n",
       "    0.08975767678022385,\n",
       "    0.08277187969287236,\n",
       "    0.08324039473136266,\n",
       "    0.07439522630307409,\n",
       "    0.07681935047441059,\n",
       "    0.07486105888419681,\n",
       "    0.07058690167797936,\n",
       "    0.06990459573931164,\n",
       "    0.07092538833618164,\n",
       "    0.06774145309130351,\n",
       "    0.06461538560854065,\n",
       "    0.059501276655329595,\n",
       "    0.06158073641194237,\n",
       "    0.05821869009070926,\n",
       "    0.05665010934405856,\n",
       "    0.0555259169737498,\n",
       "    0.05258328178524971,\n",
       "    0.051687594201829695,\n",
       "    0.052116071078512405,\n",
       "    0.05324723614586724,\n",
       "    0.04967697382635541,\n",
       "    0.04771125820941395,\n",
       "    0.04669379057486852,\n",
       "    0.04464992861615287,\n",
       "    0.04074724947412809,\n",
       "    0.041546604378355875,\n",
       "    0.04040722423791886,\n",
       "    0.041364059931702085,\n",
       "    0.03960150527954102,\n",
       "    0.039666567484537764,\n",
       "    0.037531730390257305],\n",
       "   'eval_loss': [1.2404170036315918,\n",
       "    0.9266946315765381,\n",
       "    0.7787514328956604,\n",
       "    0.5951988697052002,\n",
       "    0.4321151375770569,\n",
       "    0.3457390069961548,\n",
       "    0.32028770446777344,\n",
       "    0.2791246473789215,\n",
       "    0.24923840165138245,\n",
       "    0.24720291793346405,\n",
       "    0.22363875806331635,\n",
       "    0.22061419486999512,\n",
       "    0.20418989658355713,\n",
       "    0.20828120410442352,\n",
       "    0.2000705599784851,\n",
       "    0.20660249888896942,\n",
       "    0.17975136637687683,\n",
       "    0.17470550537109375,\n",
       "    0.16683219373226166,\n",
       "    0.1654612272977829,\n",
       "    0.1736627221107483,\n",
       "    0.18166233599185944,\n",
       "    0.15708020329475403,\n",
       "    0.16333286464214325,\n",
       "    0.15706096589565277,\n",
       "    0.15040121972560883,\n",
       "    0.14926375448703766,\n",
       "    0.15082480013370514,\n",
       "    0.1472340226173401,\n",
       "    0.15939809381961823,\n",
       "    0.14165955781936646,\n",
       "    0.15000098943710327,\n",
       "    0.14407506585121155,\n",
       "    0.1516948640346527,\n",
       "    0.15409418940544128,\n",
       "    0.14607441425323486,\n",
       "    0.15121176838874817,\n",
       "    0.1525638848543167,\n",
       "    0.15750230848789215,\n",
       "    0.14394742250442505,\n",
       "    0.1391136795282364,\n",
       "    0.13778254389762878,\n",
       "    0.14940091967582703,\n",
       "    0.14758196473121643,\n",
       "    0.1421898603439331,\n",
       "    0.14864662289619446,\n",
       "    0.15774285793304443,\n",
       "    0.13915491104125977,\n",
       "    0.13825900852680206,\n",
       "    0.13923855125904083,\n",
       "    0.13447652757167816,\n",
       "    0.13831162452697754,\n",
       "    0.13698895275592804,\n",
       "    0.13597989082336426,\n",
       "    0.1428445428609848,\n",
       "    0.1376284956932068,\n",
       "    0.1431555449962616,\n",
       "    0.13716267049312592,\n",
       "    0.13292570412158966,\n",
       "    0.14745566248893738,\n",
       "    0.1403161585330963,\n",
       "    0.14422830939292908,\n",
       "    0.14520025253295898,\n",
       "    0.13863034546375275,\n",
       "    0.14069928228855133,\n",
       "    0.13932782411575317,\n",
       "    0.13410094380378723,\n",
       "    0.1558595895767212,\n",
       "    0.1371651440858841],\n",
       "   'eval_acc': [0.011,\n",
       "    0.007,\n",
       "    0.006,\n",
       "    0.005,\n",
       "    0.007,\n",
       "    0.008,\n",
       "    0.007,\n",
       "    0.001,\n",
       "    0.005,\n",
       "    0.003,\n",
       "    0.004,\n",
       "    0.003,\n",
       "    0.002,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.003,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.003,\n",
       "    0.003,\n",
       "    0.002,\n",
       "    0.001,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.001,\n",
       "    0.002,\n",
       "    0.0,\n",
       "    0.001,\n",
       "    0.002,\n",
       "    0.002,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.002,\n",
       "    0.002,\n",
       "    0.002,\n",
       "    0.003,\n",
       "    0.001,\n",
       "    0.002,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.002,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.001,\n",
       "    0.002,\n",
       "    0.001,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.001,\n",
       "    0.0,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.001,\n",
       "    0.0,\n",
       "    0.001,\n",
       "    0.0,\n",
       "    0.001],\n",
       "   'eval_rmse': [2.530569996109243,\n",
       "    2.0498505725519767,\n",
       "    1.7936998214526216,\n",
       "    1.48219016840367,\n",
       "    1.1531535466769123,\n",
       "    0.9912560013873603,\n",
       "    0.9438333813883236,\n",
       "    0.8673360889966713,\n",
       "    0.812763754265282,\n",
       "    0.8047553318902144,\n",
       "    0.7583877756327343,\n",
       "    0.7560131935973268,\n",
       "    0.7185754996504659,\n",
       "    0.7265028537345019,\n",
       "    0.7093048159572188,\n",
       "    0.7272955531381883,\n",
       "    0.6674036047359824,\n",
       "    0.652096853227788,\n",
       "    0.6351325782284226,\n",
       "    0.6340855892584284,\n",
       "    0.65084849217435,\n",
       "    0.6707954626668066,\n",
       "    0.6158533179619898,\n",
       "    0.6256561334556939,\n",
       "    0.613653416800168,\n",
       "    0.5991621822495315,\n",
       "    0.5958840486866271,\n",
       "    0.5963051176153621,\n",
       "    0.5931315309615848,\n",
       "    0.6176212215486865,\n",
       "    0.5794934184874859,\n",
       "    0.5954342203865106,\n",
       "    0.5824430170961469,\n",
       "    0.6017218403690224,\n",
       "    0.6099168931391049,\n",
       "    0.5921028413540872,\n",
       "    0.5965208782625508,\n",
       "    0.6060590536386663,\n",
       "    0.6106448774378983,\n",
       "    0.5862597030780173,\n",
       "    0.5712062773885849,\n",
       "    0.5680610166917774,\n",
       "    0.5939893980096923,\n",
       "    0.5917558343167532,\n",
       "    0.5773105186083425,\n",
       "    0.5911777822680719,\n",
       "    0.6162550973842597,\n",
       "    0.5707161991572245,\n",
       "    0.5714037255834766,\n",
       "    0.5703172088846697,\n",
       "    0.5616520301126735,\n",
       "    0.5656874390030535,\n",
       "    0.5647356829540369,\n",
       "    0.5614653026971591,\n",
       "    0.5785512223883753,\n",
       "    0.5647269646442908,\n",
       "    0.5818225296898424,\n",
       "    0.5649087243634844,\n",
       "    0.5550314734530264,\n",
       "    0.5874788407648007,\n",
       "    0.5735042323228203,\n",
       "    0.5850863957526202,\n",
       "    0.5880587297723403,\n",
       "    0.5700764351620609,\n",
       "    0.573666932984637,\n",
       "    0.571908120341003,\n",
       "    0.5599461338839321,\n",
       "    0.6094827629074099,\n",
       "    0.568362176038344]},\n",
       "  'metrics': {'acc': 0.0,\n",
       "   'macro_f1': 0.0,\n",
       "   'pair_acc': 0.023,\n",
       "   'rmse_per_class': [0.49303746223449707,\n",
       "    0.5188505053520203,\n",
       "    0.5679834485054016,\n",
       "    0.5762630105018616,\n",
       "    0.59776371717453,\n",
       "    0.5692645907402039],\n",
       "   'mae_per_class': [0.27286794781684875,\n",
       "    0.28720545768737793,\n",
       "    0.33015206456184387,\n",
       "    0.31675031781196594,\n",
       "    0.3304028809070587,\n",
       "    0.32325491309165955],\n",
       "   'overall_rmse': 0.5550314784049988,\n",
       "   'overall_mae': 0.3101056218147278,\n",
       "   'confusion_matrix': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], shape=(135, 135))}},\n",
       " ('multitask',\n",
       "  0.3): {'history': {'train_loss': [5.156150773790148,\n",
       "    5.059788069407145,\n",
       "    3.806618108961317,\n",
       "    3.277521135542128,\n",
       "    3.0392979634602866,\n",
       "    2.639630887137519,\n",
       "    2.1698838274214003,\n",
       "    1.9064133599599202,\n",
       "    1.777245781156752,\n",
       "    1.6869987954033745,\n",
       "    1.6047288744184707,\n",
       "    1.5581342572106256,\n",
       "    1.5196810950173272,\n",
       "    1.4764465091493395,\n",
       "    1.4491805630789862,\n",
       "    1.4024475622177124,\n",
       "    1.3529164028167724,\n",
       "    1.3205712667041354,\n",
       "    1.290184327337477,\n",
       "    1.2845020756191678,\n",
       "    1.2523121274312337,\n",
       "    1.2340448518329197,\n",
       "    1.197102643330892,\n",
       "    1.1874661341773138,\n",
       "    1.158326573477851,\n",
       "    1.1313973209593031,\n",
       "    1.1200361153284708,\n",
       "    1.0876025674608019,\n",
       "    1.071049776977963,\n",
       "    1.0684111215803358,\n",
       "    1.0335832601123387,\n",
       "    1.0124663647545709,\n",
       "    0.9875136293835111,\n",
       "    1.0123319419754877,\n",
       "    0.9489977911843194,\n",
       "    0.9360164102448357,\n",
       "    0.9269657259517246,\n",
       "    0.9216189686457316,\n",
       "    0.8701991795433892,\n",
       "    0.8724447816212972],\n",
       "   'eval_loss': [5.1056294441223145,\n",
       "    4.55396842956543,\n",
       "    3.3136441707611084,\n",
       "    2.984567165374756,\n",
       "    2.795624256134033,\n",
       "    2.4582276344299316,\n",
       "    1.948575496673584,\n",
       "    1.7998346090316772,\n",
       "    1.6608705520629883,\n",
       "    1.5613296031951904,\n",
       "    1.5575364828109741,\n",
       "    1.5362052917480469,\n",
       "    1.489272952079773,\n",
       "    1.4123715162277222,\n",
       "    1.5952813625335693,\n",
       "    1.428398847579956,\n",
       "    1.431504487991333,\n",
       "    1.3688172101974487,\n",
       "    1.3673440217971802,\n",
       "    1.351678490638733,\n",
       "    1.2920539379119873,\n",
       "    1.286702275276184,\n",
       "    1.2791473865509033,\n",
       "    1.3238950967788696,\n",
       "    1.249923586845398,\n",
       "    1.3366539478302002,\n",
       "    1.2725647687911987,\n",
       "    1.2806693315505981,\n",
       "    1.3663356304168701,\n",
       "    1.2248471975326538,\n",
       "    1.2424499988555908,\n",
       "    1.3661404848098755,\n",
       "    1.297485113143921,\n",
       "    1.3321247100830078,\n",
       "    1.3131103515625,\n",
       "    1.25739324092865,\n",
       "    1.3364081382751465,\n",
       "    1.3019295930862427,\n",
       "    1.295151948928833,\n",
       "    1.2901686429977417],\n",
       "   'eval_acc': [0.011,\n",
       "    0.026,\n",
       "    0.1,\n",
       "    0.123,\n",
       "    0.169,\n",
       "    0.219,\n",
       "    0.315,\n",
       "    0.337,\n",
       "    0.341,\n",
       "    0.389,\n",
       "    0.388,\n",
       "    0.409,\n",
       "    0.425,\n",
       "    0.441,\n",
       "    0.372,\n",
       "    0.429,\n",
       "    0.444,\n",
       "    0.466,\n",
       "    0.462,\n",
       "    0.464,\n",
       "    0.489,\n",
       "    0.507,\n",
       "    0.484,\n",
       "    0.485,\n",
       "    0.501,\n",
       "    0.486,\n",
       "    0.493,\n",
       "    0.513,\n",
       "    0.469,\n",
       "    0.521,\n",
       "    0.501,\n",
       "    0.471,\n",
       "    0.505,\n",
       "    0.489,\n",
       "    0.474,\n",
       "    0.499,\n",
       "    0.488,\n",
       "    0.504,\n",
       "    0.495,\n",
       "    0.51],\n",
       "   'eval_rmse': [2.8784956104129575,\n",
       "    2.4540785036512855,\n",
       "    2.071206057168142,\n",
       "    1.9115529041092043,\n",
       "    1.684116012865998,\n",
       "    1.2970592238630947,\n",
       "    1.0333692712584646,\n",
       "    0.948457792547877,\n",
       "    0.8530576514930472,\n",
       "    0.8238477393646535,\n",
       "    0.7857708777982506,\n",
       "    0.7792759434845593,\n",
       "    0.7726871886711066,\n",
       "    0.7276163951489709,\n",
       "    0.7666645790845672,\n",
       "    0.7042656257510964,\n",
       "    0.6882235479974724,\n",
       "    0.6786178424612566,\n",
       "    0.6697546484067879,\n",
       "    0.6714011167963728,\n",
       "    0.6493486319638575,\n",
       "    0.6494589094007411,\n",
       "    0.615745216160027,\n",
       "    0.6492370196486732,\n",
       "    0.6031747537228708,\n",
       "    0.6294859840907235,\n",
       "    0.6112167014404888,\n",
       "    0.6140927155415947,\n",
       "    0.6662863193176758,\n",
       "    0.6034446678216618,\n",
       "    0.6109042310314993,\n",
       "    0.6262995928571412,\n",
       "    0.5997929872915877,\n",
       "    0.6005191845525212,\n",
       "    0.6071265945607363,\n",
       "    0.5776798328294077,\n",
       "    0.6102847109222193,\n",
       "    0.5962510714198096,\n",
       "    0.5923748466844072,\n",
       "    0.6035639054986914]}, 'metrics': {'acc': 0.5210000276565552,\n",
       "   'macro_f1': 0.5001977216209628,\n",
       "   'pair_acc': 0.953,\n",
       "   'rmse_per_class': [0.5626434087753296,\n",
       "    0.5422553420066833,\n",
       "    0.6271865963935852,\n",
       "    0.6286020278930664,\n",
       "    0.5878118276596069,\n",
       "    0.6635043621063232],\n",
       "   'mae_per_class': [0.3303215503692627,\n",
       "    0.3346816897392273,\n",
       "    0.3768671751022339,\n",
       "    0.38134998083114624,\n",
       "    0.3539736270904541,\n",
       "    0.397741436958313],\n",
       "   'overall_rmse': 0.6034446954727173,\n",
       "   'overall_mae': 0.362489253282547,\n",
       "   'confusion_matrix': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 6, 3, ..., 0, 0, 0],\n",
       "          [0, 1, 5, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 6, 0, 0],\n",
       "          [0, 0, 0, ..., 5, 7, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]], shape=(135, 135))}},\n",
       " ('multitask',\n",
       "  0.5): {'history': {'train_loss': [5.438821768442789,\n",
       "    4.949407769097222,\n",
       "    4.160285743289523,\n",
       "    3.335883702596029,\n",
       "    2.68748329310947,\n",
       "    2.3069785895877413,\n",
       "    2.0661583137512207,\n",
       "    1.9493075320985582,\n",
       "    1.8615673672358195,\n",
       "    1.783860064930386,\n",
       "    1.724952393743727,\n",
       "    1.6737141926023695,\n",
       "    1.5986524998346965,\n",
       "    1.5620170376035902,\n",
       "    1.533506759431627,\n",
       "    1.5070021571053398,\n",
       "    1.4701127624511718,\n",
       "    1.436436579598321,\n",
       "    1.4116442201402453,\n",
       "    1.364671940697564,\n",
       "    1.357241797235277,\n",
       "    1.317464451683892,\n",
       "    1.3254972268210516,\n",
       "    1.286091242896186,\n",
       "    1.2403816355599298,\n",
       "    1.234920682059394,\n",
       "    1.2129257230758668,\n",
       "    1.191056719991896,\n",
       "    1.167688555823432,\n",
       "    1.1689703543980916,\n",
       "    1.1401932241651747,\n",
       "    1.1086240733464559,\n",
       "    1.093736576822069,\n",
       "    1.0795530060662164,\n",
       "    1.0700156455569798,\n",
       "    1.0367974934048123,\n",
       "    1.0300154146618312,\n",
       "    1.0212972492641872,\n",
       "    0.9911008302370707,\n",
       "    0.9731625804371304,\n",
       "    0.9757596385214063,\n",
       "    0.9364708950254652,\n",
       "    0.9257125261094835,\n",
       "    0.9112099580764771,\n",
       "    0.9082819470829434,\n",
       "    0.8712270435757107,\n",
       "    0.8849489814440409,\n",
       "    0.8555582408375211,\n",
       "    0.8386426137288412],\n",
       "   'eval_loss': [5.380980491638184,\n",
       "    4.545534133911133,\n",
       "    3.956709861755371,\n",
       "    2.9053781032562256,\n",
       "    2.5519750118255615,\n",
       "    2.1233749389648438,\n",
       "    2.0407679080963135,\n",
       "    1.9852739572525024,\n",
       "    1.8339731693267822,\n",
       "    1.7969849109649658,\n",
       "    1.7332061529159546,\n",
       "    1.6606600284576416,\n",
       "    1.6126174926757812,\n",
       "    1.5493873357772827,\n",
       "    1.5330274105072021,\n",
       "    1.4771144390106201,\n",
       "    1.6268001794815063,\n",
       "    1.5315688848495483,\n",
       "    1.464402437210083,\n",
       "    1.4425697326660156,\n",
       "    1.404374361038208,\n",
       "    1.3818163871765137,\n",
       "    1.3397579193115234,\n",
       "    1.4138555526733398,\n",
       "    1.4197967052459717,\n",
       "    1.4194085597991943,\n",
       "    1.3399739265441895,\n",
       "    1.3270021677017212,\n",
       "    1.3156428337097168,\n",
       "    1.332148551940918,\n",
       "    1.339214563369751,\n",
       "    1.2812472581863403,\n",
       "    1.333971619606018,\n",
       "    1.2522603273391724,\n",
       "    1.2375550270080566,\n",
       "    1.2963863611221313,\n",
       "    1.2424612045288086,\n",
       "    1.313464641571045,\n",
       "    1.2315540313720703,\n",
       "    1.2989410161972046,\n",
       "    1.3321831226348877,\n",
       "    1.2630128860473633,\n",
       "    1.2834062576293945,\n",
       "    1.3003851175308228,\n",
       "    1.3057080507278442,\n",
       "    1.304887056350708,\n",
       "    1.2762657403945923,\n",
       "    1.2719396352767944,\n",
       "    1.3484501838684082],\n",
       "   'eval_acc': [0.009,\n",
       "    0.034,\n",
       "    0.089,\n",
       "    0.165,\n",
       "    0.205,\n",
       "    0.288,\n",
       "    0.273,\n",
       "    0.292,\n",
       "    0.356,\n",
       "    0.332,\n",
       "    0.372,\n",
       "    0.379,\n",
       "    0.366,\n",
       "    0.403,\n",
       "    0.399,\n",
       "    0.435,\n",
       "    0.389,\n",
       "    0.397,\n",
       "    0.435,\n",
       "    0.44,\n",
       "    0.434,\n",
       "    0.452,\n",
       "    0.502,\n",
       "    0.441,\n",
       "    0.429,\n",
       "    0.425,\n",
       "    0.462,\n",
       "    0.466,\n",
       "    0.478,\n",
       "    0.464,\n",
       "    0.468,\n",
       "    0.498,\n",
       "    0.464,\n",
       "    0.514,\n",
       "    0.511,\n",
       "    0.509,\n",
       "    0.513,\n",
       "    0.511,\n",
       "    0.514,\n",
       "    0.508,\n",
       "    0.495,\n",
       "    0.513,\n",
       "    0.517,\n",
       "    0.501,\n",
       "    0.494,\n",
       "    0.495,\n",
       "    0.519,\n",
       "    0.504,\n",
       "    0.506],\n",
       "   'eval_rmse': [2.884394862697951,\n",
       "    2.5261133580891943,\n",
       "    2.1049117905112635,\n",
       "    1.5642771664207775,\n",
       "    1.2838357419232351,\n",
       "    1.0327290529829205,\n",
       "    0.9926314623525104,\n",
       "    0.9284516470648863,\n",
       "    0.8833416095082025,\n",
       "    0.8559770892633459,\n",
       "    0.8289729346016572,\n",
       "    0.790600990865691,\n",
       "    0.7281461795024117,\n",
       "    0.7255855326799006,\n",
       "    0.7097585806727112,\n",
       "    0.71015607810779,\n",
       "    0.7468596908298495,\n",
       "    0.7076664963930308,\n",
       "    0.6899685204737906,\n",
       "    0.657663222868317,\n",
       "    0.6482751428269418,\n",
       "    0.6475419895691772,\n",
       "    0.6420710939713309,\n",
       "    0.6352659486552331,\n",
       "    0.6425911140404527,\n",
       "    0.6394761357471475,\n",
       "    0.6055605777139477,\n",
       "    0.6021665325120653,\n",
       "    0.6026913110426017,\n",
       "    0.5964097499569821,\n",
       "    0.600793745806329,\n",
       "    0.580112048320642,\n",
       "    0.5939290094735825,\n",
       "    0.584954174887871,\n",
       "    0.572792162134403,\n",
       "    0.5801991929636106,\n",
       "    0.5693924156342186,\n",
       "    0.5872766641101392,\n",
       "    0.5567168167884388,\n",
       "    0.5770504160098904,\n",
       "    0.5836593559732459,\n",
       "    0.568765506742591,\n",
       "    0.5670628916437991,\n",
       "    0.5654051857637509,\n",
       "    0.5560367978586639,\n",
       "    0.5612439136699038,\n",
       "    0.5568123181847647,\n",
       "    0.5519570045127874,\n",
       "    0.5569712742372993]}, 'metrics': {'acc': 0.5139999985694885,\n",
       "   'macro_f1': 0.47920870414535816,\n",
       "   'pair_acc': 0.952,\n",
       "   'rmse_per_class': [0.4578821063041687,\n",
       "    0.48316025733947754,\n",
       "    0.5726819634437561,\n",
       "    0.6212713718414307,\n",
       "    0.5431850552558899,\n",
       "    0.6383643746376038],\n",
       "   'mae_per_class': [0.281477689743042,\n",
       "    0.29874199628829956,\n",
       "    0.3659662902355194,\n",
       "    0.3448461890220642,\n",
       "    0.3268200755119324,\n",
       "    0.37309974431991577],\n",
       "   'overall_rmse': 0.556716799736023,\n",
       "   'overall_mae': 0.3318253457546234,\n",
       "   'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "          [ 0, 10,  0, ...,  0,  0,  0],\n",
       "          [ 0,  2,  1, ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0, ...,  3,  1,  0],\n",
       "          [ 0,  0,  0, ...,  1,  9,  0],\n",
       "          [ 0,  0,  0, ...,  0,  0,  0]], shape=(135, 135))}},\n",
       " ('multitask',\n",
       "  1.0): {'history': {'train_loss': [6.146042611016168,\n",
       "    6.0795694287618005,\n",
       "    5.328925315856933,\n",
       "    4.630917971081204,\n",
       "    3.37677428372701,\n",
       "    2.5191670405069986,\n",
       "    2.143474190182156,\n",
       "    2.0066705038282606,\n",
       "    1.8838615631527371,\n",
       "    1.8073279063966539,\n",
       "    1.720861789279514,\n",
       "    1.6514233167436387,\n",
       "    1.5823584373262194,\n",
       "    1.5502271093792386,\n",
       "    1.5075390847524006,\n",
       "    1.4752497460047405,\n",
       "    1.4479407252205743,\n",
       "    1.4098181141747368,\n",
       "    1.392216718673706,\n",
       "    1.3448806940714517,\n",
       "    1.3439325343237982,\n",
       "    1.2879598659939235,\n",
       "    1.271151756392585,\n",
       "    1.24621209303538,\n",
       "    1.2234325521257188,\n",
       "    1.2246035419040255,\n",
       "    1.176021967464023,\n",
       "    1.1809913919236925,\n",
       "    1.1210946782430014,\n",
       "    1.1208070936203003,\n",
       "    1.0772336027887133,\n",
       "    1.0687680118878682,\n",
       "    1.0645004970762464,\n",
       "    1.0296290832095676,\n",
       "    1.02258192814721,\n",
       "    1.0003837957382202,\n",
       "    0.9942952612770928,\n",
       "    0.960983213212755,\n",
       "    0.9698274597062005,\n",
       "    0.9226395280626085,\n",
       "    0.9203796430693733,\n",
       "    0.8956868126127455,\n",
       "    0.8948055178854201,\n",
       "    0.8694674081272549],\n",
       "   'eval_loss': [6.100281238555908,\n",
       "    5.909855842590332,\n",
       "    5.02687406539917,\n",
       "    4.13362979888916,\n",
       "    2.6746959686279297,\n",
       "    2.2550859451293945,\n",
       "    2.0475964546203613,\n",
       "    1.8986265659332275,\n",
       "    1.811059594154358,\n",
       "    1.680757761001587,\n",
       "    1.6924536228179932,\n",
       "    1.62279212474823,\n",
       "    1.5639667510986328,\n",
       "    1.5506563186645508,\n",
       "    1.5384504795074463,\n",
       "    1.5164179801940918,\n",
       "    1.517396092414856,\n",
       "    1.5133585929870605,\n",
       "    1.5072365999221802,\n",
       "    1.5254685878753662,\n",
       "    1.421006679534912,\n",
       "    1.4709372520446777,\n",
       "    1.4015073776245117,\n",
       "    1.421149492263794,\n",
       "    1.4217709302902222,\n",
       "    1.437429428100586,\n",
       "    1.4119685888290405,\n",
       "    1.4248850345611572,\n",
       "    1.4122872352600098,\n",
       "    1.375870704650879,\n",
       "    1.404195785522461,\n",
       "    1.429947853088379,\n",
       "    1.4160689115524292,\n",
       "    1.3712763786315918,\n",
       "    1.528913974761963,\n",
       "    1.3963704109191895,\n",
       "    1.4485206604003906,\n",
       "    1.389192819595337,\n",
       "    1.4364582300186157,\n",
       "    1.5327013731002808,\n",
       "    1.3791675567626953,\n",
       "    1.4596118927001953,\n",
       "    1.4313682317733765,\n",
       "    1.4275990724563599],\n",
       "   'eval_acc': [0.005,\n",
       "    0.018,\n",
       "    0.035,\n",
       "    0.091,\n",
       "    0.251,\n",
       "    0.257,\n",
       "    0.297,\n",
       "    0.357,\n",
       "    0.373,\n",
       "    0.393,\n",
       "    0.383,\n",
       "    0.391,\n",
       "    0.4,\n",
       "    0.416,\n",
       "    0.428,\n",
       "    0.43,\n",
       "    0.437,\n",
       "    0.454,\n",
       "    0.429,\n",
       "    0.439,\n",
       "    0.454,\n",
       "    0.454,\n",
       "    0.485,\n",
       "    0.459,\n",
       "    0.455,\n",
       "    0.45,\n",
       "    0.467,\n",
       "    0.471,\n",
       "    0.477,\n",
       "    0.482,\n",
       "    0.48,\n",
       "    0.476,\n",
       "    0.48,\n",
       "    0.484,\n",
       "    0.47,\n",
       "    0.482,\n",
       "    0.48,\n",
       "    0.511,\n",
       "    0.485,\n",
       "    0.467,\n",
       "    0.506,\n",
       "    0.486,\n",
       "    0.5,\n",
       "    0.476],\n",
       "   'eval_rmse': [2.894930239876256,\n",
       "    2.7068586930933427,\n",
       "    2.470514269379623,\n",
       "    1.9334990612337175,\n",
       "    1.1536606705215937,\n",
       "    0.9348606945578398,\n",
       "    0.8659179896755523,\n",
       "    0.8151233191306853,\n",
       "    0.7899784803075071,\n",
       "    0.728744985956879,\n",
       "    0.7096266245632716,\n",
       "    0.676077457963706,\n",
       "    0.6581116018836426,\n",
       "    0.6648201866172945,\n",
       "    0.6642790700772593,\n",
       "    0.6383755604029587,\n",
       "    0.6392471844995682,\n",
       "    0.6525738117275349,\n",
       "    0.6654186519942727,\n",
       "    0.6671656661142468,\n",
       "    0.6006581405615982,\n",
       "    0.6439748229481846,\n",
       "    0.5984455232273305,\n",
       "    0.599149991980827,\n",
       "    0.6029091393722122,\n",
       "    0.5970489493472597,\n",
       "    0.5937788507245002,\n",
       "    0.5939942959598287,\n",
       "    0.5865776364367365,\n",
       "    0.5820303761179122,\n",
       "    0.5714753591365601,\n",
       "    0.5936908207898318,\n",
       "    0.5911729986416131,\n",
       "    0.5659971942450149,\n",
       "    0.6217825386665542,\n",
       "    0.5874916887709987,\n",
       "    0.5813623813289601,\n",
       "    0.5782517632703427,\n",
       "    0.5969250019959061,\n",
       "    0.6115539302755045,\n",
       "    0.542632427313255,\n",
       "    0.5664503215612778,\n",
       "    0.5892076799433004,\n",
       "    0.5700828947056187]}, 'metrics': {'acc': 0.48399999737739563,\n",
       "   'macro_f1': 0.4518037611892341,\n",
       "   'pair_acc': 0.947,\n",
       "   'rmse_per_class': [0.46826133131980896,\n",
       "    0.4819292426109314,\n",
       "    0.5908148884773254,\n",
       "    0.605099081993103,\n",
       "    0.5845974087715149,\n",
       "    0.6431415677070618],\n",
       "   'mae_per_class': [0.27131927013397217,\n",
       "    0.2920176386833191,\n",
       "    0.3304550349712372,\n",
       "    0.3383287489414215,\n",
       "    0.32832419872283936,\n",
       "    0.3672081232070923],\n",
       "   'overall_rmse': 0.5659971833229065,\n",
       "   'overall_mae': 0.3212755024433136,\n",
       "   'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "          [ 0,  4,  6, ...,  0,  0,  0],\n",
       "          [ 0,  0,  4, ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0, ...,  3,  2,  0],\n",
       "          [ 0,  0,  0, ...,  0, 10,  0],\n",
       "          [ 0,  0,  0, ...,  0,  0,  0]], shape=(135, 135))}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = [\n",
    "    (\"cls_only\", None),\n",
    "    (\"reg_only\", None),\n",
    "    (\"multitask\", 0.3),\n",
    "    (\"multitask\", 0.5),\n",
    "    (\"multitask\", 1.0),\n",
    "]\n",
    "\n",
    "train_multiple_models(settings, \"models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
